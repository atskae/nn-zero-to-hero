{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b908cb-2c1d-4c2b-84b2-ea18867ea87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f35433-59bd-4577-bb93-03eca7539002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in all the names, as a list of names\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40047ee-fc04-4e80-a573-19052e8ae9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 names\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(words)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5213b782-cce5-4d0a-a3ab-50b29a3d8446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build character to integer mapping\n",
    "# First we combine all the names into one string, then create a set() (this keeps unique characters only)\n",
    "# Then we sort alphabetically\n",
    "chars = sorted(set(\"\".join(words)))\n",
    "\n",
    "# String to integer\n",
    "stoi = {c:i+1 for (i, c) in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4e9349-6c01-4bc3-889f-733804ea339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer to string\n",
    "itos = {i:c for (c,i) in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3345086",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb5b5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# Context length: how many previous characters do we use to predict the next character\n",
    "block_size = 3\n",
    "\n",
    "# Inputs to the neural net (the previous characters seen)\n",
    "X = []\n",
    "# The labels of the inputs to the neural net (the next character)\n",
    "Y = []\n",
    "\n",
    "# Create a dataset, mapping `block_size` characters -> next character\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    \n",
    "    # Initialize the context with empty characters\n",
    "    context = [stoi[\".\"]] * block_size\n",
    "    # We want the last characters of the name to be included in the dataset\n",
    "    # which is why we append \".\" to the end of the name\n",
    "    for w in word + \".\":\n",
    "        # Get the next character\n",
    "        ix = stoi[w]\n",
    "        \n",
    "        # Save the input and output\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "            \n",
    "        # Print the example\n",
    "        print(\"\".join(itos[i] for i in context) + \" ---> \" + itos[ix])\n",
    "        \n",
    "        # Remove the earliest character in the context, and append the newest character\n",
    "        # as the latest character in the context\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "# Inputs\n",
    "X = torch.tensor(X)\n",
    "# Labels\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4ed7c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 3]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# We have x many input examples, with each with a context size `block_size`\n",
    "print(f\"Input shape: {X.shape}, {X.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6d7531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([27]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# The next character is one of 27 possible characters\n",
    "print(f\"Labels shape: {Y.shape}, {Y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e14a4",
   "metadata": {},
   "source": [
    "## Building the Embedding Table `C`\n",
    "In the paper, 17,000 possible words are crammed into a 30-dimensional space.\n",
    "We have 27 possible characters, so let's cram them into a 2-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "706c9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 possible characters, 2-dimensional space\n",
    "# Each character has a 2-dimenional embedding\n",
    "C = torch.randn((27, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be366943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character g maps to 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1250, -0.0114])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 'g'\n",
    "c_index = stoi[c]\n",
    "print(f\"Character {c} maps to {c_index}\")\n",
    "C[c_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24ad2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing into the embedding table `C` is the same as matrix multiplying\n",
    "# `C` with the one-hot encoding representation of the input character\n",
    "v = F.one_hot(torch.tensor(c_index), num_classes=27)\n",
    "v.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11319dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6429, 0.3626])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to cast the vector to a float since the embedding table C contains floats\n",
    "v.float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01618549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
