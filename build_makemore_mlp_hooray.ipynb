{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b908cb-2c1d-4c2b-84b2-ea18867ea87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f35433-59bd-4577-bb93-03eca7539002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in all the names, as a list of names\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d40047ee-fc04-4e80-a573-19052e8ae9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(words)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5213b782-cce5-4d0a-a3ab-50b29a3d8446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build character to integer mapping\n",
    "# First we combine all the names into one string, then create a set() (this keeps unique characters only)\n",
    "# Then we sort alphabetically\n",
    "chars = sorted(set(\"\".join(words)))\n",
    "\n",
    "# String to integer\n",
    "stoi = {c:i+1 for (i, c) in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e9349-6c01-4bc3-889f-733804ea339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer to string\n",
    "itos = {i:c for (c,i) in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3345086",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5b5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# Context length: how many previous characters do we use to predict the next character\n",
    "block_size = 3\n",
    "\n",
    "# Inputs to the neural net (the previous characters seen)\n",
    "X = []\n",
    "# The labels of the inputs to the neural net (the next character)\n",
    "Y = []\n",
    "\n",
    "# Create a dataset, mapping `block_size` characters -> next character\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    \n",
    "    # Initialize the context with empty characters\n",
    "    context = [stoi[\".\"]] * block_size\n",
    "    # We want the last characters of the name to be included in the dataset\n",
    "    # which is why we append \".\" to the end of the name\n",
    "    for w in word + \".\":\n",
    "        # Get the next character\n",
    "        ix = stoi[w]\n",
    "        \n",
    "        # Save the input and output\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "            \n",
    "        # Print the example\n",
    "        print(\"\".join(itos[i] for i in context) + \" ---> \" + itos[ix])\n",
    "        \n",
    "        # Remove the earliest character in the context, and append the newest character\n",
    "        # as the latest character in the context\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "# Inputs\n",
    "X = torch.tensor(X)\n",
    "# Labels\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ed7c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 3]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# We have x many input examples, with each with a context size `block_size`\n",
    "print(f\"Input shape: {X.shape}, {X.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6d7531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([32]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# The next character is one of 27 possible characters\n",
    "print(f\"Labels shape: {Y.shape}, {Y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e14a4",
   "metadata": {},
   "source": [
    "## Building the Embedding Table `C`\n",
    "In the paper, 17,000 possible words are crammed into a 30-dimensional space.\n",
    "We have 27 possible characters, so let's cram them into a 2-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706c9aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1067, -0.3255],\n",
       "        [ 0.3376,  0.3419],\n",
       "        [ 0.1550, -1.1830],\n",
       "        [ 1.5495, -0.5934],\n",
       "        [ 0.2971, -0.6370],\n",
       "        [ 0.7099, -1.3830],\n",
       "        [ 0.7070, -0.6605],\n",
       "        [ 1.7801,  1.2121],\n",
       "        [ 0.1998,  0.2748],\n",
       "        [ 0.6895,  0.9553],\n",
       "        [ 0.9003,  1.3806],\n",
       "        [ 0.3174, -0.4722],\n",
       "        [ 0.8947,  0.9249],\n",
       "        [-0.2009, -0.5896],\n",
       "        [ 0.5659, -0.1542],\n",
       "        [ 0.6248,  0.4970],\n",
       "        [-0.6143,  0.1434],\n",
       "        [-0.4804,  0.7898],\n",
       "        [-0.6984,  1.8530],\n",
       "        [-0.4805,  0.5944],\n",
       "        [-0.8023,  1.0666],\n",
       "        [ 0.7912, -0.0591],\n",
       "        [-0.3390,  1.2435],\n",
       "        [ 1.0390,  2.1184],\n",
       "        [-1.8662,  1.3436],\n",
       "        [-0.1631,  0.7092],\n",
       "        [ 0.4480,  1.0854]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 27 possible characters, 2-dimensional space\n",
    "# Each character has a 2-dimenional embedding\n",
    "C = torch.randn((27, 2))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be366943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character g maps to 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.7801, 1.2121])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 'g'\n",
    "c_index = stoi[c]\n",
    "print(f\"Character {c} maps to {c_index}\")\n",
    "C[c_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ad2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing into the embedding table `C` is the same as matrix multiplying\n",
    "# `C` with the one-hot encoding representation of the input character\n",
    "v = F.one_hot(torch.tensor(c_index), num_classes=27)\n",
    "v.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11319dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7801, 1.2121])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to cast the vector to a float since the embedding table C contains floats\n",
    "v.float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7679b9",
   "metadata": {},
   "source": [
    "Embedding a single character into the embedding table `C` is easy. Just use the integer representation of that character, and index into `C`. But how do we simultaneously embed `[32,3]` (32 examples, each of size 3, stored in array `X`) into `C`?\n",
    "\n",
    "In addition to integers, we can use lists to index into `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b70c525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1550, -1.1830],\n",
       "        [ 1.5495, -0.5934],\n",
       "        [ 0.2971, -0.6370]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets the rows at index 2, 3, and 4\n",
    "C[[2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1f150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1550, -1.1830],\n",
       "        [ 1.5495, -0.5934],\n",
       "        [ 0.2971, -0.6370]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also index using Tensors\n",
    "C[torch.tensor([2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15f21f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1550, -1.1830],\n",
       "        [ 0.1550, -1.1830],\n",
       "        [ 0.1550, -1.1830]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the same row multiple times\n",
    "C[[2,2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a89bbac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall, X contains the characters as integers as input\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf02c925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape torch.Size([32, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.7099, -1.3830]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [ 0.7099, -1.3830],\n",
       "         [-0.2009, -0.5896]],\n",
       "\n",
       "        [[ 0.7099, -1.3830],\n",
       "         [-0.2009, -0.5896],\n",
       "         [-0.2009, -0.5896]],\n",
       "\n",
       "        [[-0.2009, -0.5896],\n",
       "         [-0.2009, -0.5896],\n",
       "         [ 0.3376,  0.3419]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.6248,  0.4970]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [ 0.6248,  0.4970],\n",
       "         [ 0.8947,  0.9249]],\n",
       "\n",
       "        [[ 0.6248,  0.4970],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.6895,  0.9553]],\n",
       "\n",
       "        [[ 0.8947,  0.9249],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.3390,  1.2435]],\n",
       "\n",
       "        [[ 0.6895,  0.9553],\n",
       "         [-0.3390,  1.2435],\n",
       "         [ 0.6895,  0.9553]],\n",
       "\n",
       "        [[-0.3390,  1.2435],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [ 0.3376,  0.3419]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.3376,  0.3419]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [-0.3390,  1.2435]],\n",
       "\n",
       "        [[ 0.3376,  0.3419],\n",
       "         [-0.3390,  1.2435],\n",
       "         [ 0.3376,  0.3419]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.6895,  0.9553]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.4805,  0.5944]],\n",
       "\n",
       "        [[ 0.6895,  0.9553],\n",
       "         [-0.4805,  0.5944],\n",
       "         [ 0.3376,  0.3419]],\n",
       "\n",
       "        [[-0.4805,  0.5944],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [ 0.1550, -1.1830]],\n",
       "\n",
       "        [[ 0.3376,  0.3419],\n",
       "         [ 0.1550, -1.1830],\n",
       "         [ 0.7099, -1.3830]],\n",
       "\n",
       "        [[ 0.1550, -1.1830],\n",
       "         [ 0.7099, -1.3830],\n",
       "         [ 0.8947,  0.9249]],\n",
       "\n",
       "        [[ 0.7099, -1.3830],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.8947,  0.9249]],\n",
       "\n",
       "        [[ 0.8947,  0.9249],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.3376,  0.3419]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.4805,  0.5944]],\n",
       "\n",
       "        [[-0.1067, -0.3255],\n",
       "         [-0.4805,  0.5944],\n",
       "         [ 0.6248,  0.4970]],\n",
       "\n",
       "        [[-0.4805,  0.5944],\n",
       "         [ 0.6248,  0.4970],\n",
       "         [-0.6143,  0.1434]],\n",
       "\n",
       "        [[ 0.6248,  0.4970],\n",
       "         [-0.6143,  0.1434],\n",
       "         [ 0.1998,  0.2748]],\n",
       "\n",
       "        [[-0.6143,  0.1434],\n",
       "         [ 0.1998,  0.2748],\n",
       "         [ 0.6895,  0.9553]],\n",
       "\n",
       "        [[ 0.1998,  0.2748],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [ 0.3376,  0.3419]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can index into the embedding table `C` using multi-dimensional tensors too\n",
    "# The character integers in X is used as the indices into C\n",
    "print(\"X.shape\", X.shape)\n",
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153492e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [32, 3] was the shape of the input X, then each input has an embedding of 2\n",
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d40b09b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 2nd character in the 7th example\n",
    "example_index = 7\n",
    "character_index = 2\n",
    "X[example_index,character_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ac3582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the character representation of the integer\n",
    "itos[X[example_index,character_index].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a11182dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8947, 0.9249])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the *embedding*of the 2nd character in the 7th example\n",
    "C[X][example_index,character_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3943da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8947, 0.9249])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C[12] is equivalent to C[X[7,2]]\n",
    "C[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2de2444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We created our embedding table integrated with our example inputs!\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f5a6d",
   "metadata": {},
   "source": [
    "## Contructing the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4497a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "# 3 characters per input, and each characters has two floats that represent it (it's embedding)\n",
    "# 3*2 = 6 outputs in the first layer\n",
    "# So the hidden layer has to take in 6 inputs\n",
    "# The number of out put nodes is a variable, we arbitrary choose 100 for now\n",
    "W1 = torch.randn((6,100))\n",
    "# Biases, should match the size of the hidden layer\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff3911d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The goal is to be able to do:\n",
    "# emb @ W1 + b\n",
    "# with `@` indicating matrix multiply\n",
    "# and `emb` as our input\n",
    "# We can't do this directly since their shapes don't match correctly\n",
    "# The goal is to get the input/embedding of shape [32,6]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b26ea7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7168f7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [ 0.7099, -1.3830],\n",
       "        [-0.2009, -0.5896],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [ 0.6248,  0.4970],\n",
       "        [ 0.8947,  0.9249],\n",
       "        [ 0.6895,  0.9553],\n",
       "        [-0.3390,  1.2435],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [ 0.3376,  0.3419],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [ 0.6895,  0.9553],\n",
       "        [-0.4805,  0.5944],\n",
       "        [ 0.3376,  0.3419],\n",
       "        [ 0.1550, -1.1830],\n",
       "        [ 0.7099, -1.3830],\n",
       "        [ 0.8947,  0.9249],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255],\n",
       "        [-0.4805,  0.5944],\n",
       "        [ 0.6248,  0.4970],\n",
       "        [-0.6143,  0.1434],\n",
       "        [ 0.1998,  0.2748]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To do this, we can concatenate the three characters and their embeddings\n",
    "# This grabs all the examples, indexes that into index 0 (first character)\n",
    "# then grabs all the embeddings of the first character for all the examples\n",
    "emb[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70ac1e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets the embeddings of all the first characters in each example\n",
    "emb[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ac67b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to concatenate the embeddings of all the characters\n",
    "# Each emb[:, x, :] has shape [32, 2]\n",
    "# and we want to concatenate cross the dim=1 to get [32,6]\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 1, :]], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15fae181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.7099, -1.3830],\n",
       "         [-0.2009, -0.5896],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.6248,  0.4970],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.3390,  1.2435],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.4805,  0.5944],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [ 0.1550, -1.1830],\n",
       "         [ 0.7099, -1.3830],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.4805,  0.5944],\n",
       "         [ 0.6248,  0.4970],\n",
       "         [-0.6143,  0.1434],\n",
       "         [ 0.1998,  0.2748]]),\n",
       " tensor([[-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.7099, -1.3830],\n",
       "         [-0.2009, -0.5896],\n",
       "         [-0.2009, -0.5896],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.6248,  0.4970],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.3390,  1.2435],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [-0.3390,  1.2435],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.4805,  0.5944],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [ 0.1550, -1.1830],\n",
       "         [ 0.7099, -1.3830],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.4805,  0.5944],\n",
       "         [ 0.6248,  0.4970],\n",
       "         [-0.6143,  0.1434],\n",
       "         [ 0.1998,  0.2748],\n",
       "         [ 0.6895,  0.9553]]),\n",
       " tensor([[-0.1067, -0.3255],\n",
       "         [ 0.7099, -1.3830],\n",
       "         [-0.2009, -0.5896],\n",
       "         [-0.2009, -0.5896],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.6248,  0.4970],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.3390,  1.2435],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [-0.3390,  1.2435],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [-0.1067, -0.3255],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [-0.4805,  0.5944],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [ 0.1550, -1.1830],\n",
       "         [ 0.7099, -1.3830],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.8947,  0.9249],\n",
       "         [ 0.3376,  0.3419],\n",
       "         [-0.1067, -0.3255],\n",
       "         [-0.4805,  0.5944],\n",
       "         [ 0.6248,  0.4970],\n",
       "         [-0.6143,  0.1434],\n",
       "         [ 0.1998,  0.2748],\n",
       "         [ 0.6895,  0.9553],\n",
       "         [ 0.3376,  0.3419]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard-coding the concatenation wouldn't work for other block sizes\n",
    "# So we generalize using torch.unbind\n",
    "# For block_size 3, torch.unbind(emb, dim=1) == [emb[:, 0, :], emb[:, 1, :], emb[:, 1, :]]\n",
    "torch.unbind(emb, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc862b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, dim=1), dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78118702",
   "metadata": {},
   "source": [
    "A more efficient way to concatenate the embeddings is to use `view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d340a036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7b5e40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One list of 18 numbers\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd413e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can represent this tensor with different dimensions\n",
    "# Two lists of 9 numbers\n",
    "a.view((2,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4f26fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 lists of 3 lists of 2 numbers\n",
    "a.view([3,3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e6124",
   "metadata": {},
   "source": [
    "`view()` is very efficent because of a tensor's `storage()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe617808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/3bkxx92d0z502px7sssbxnyw0000gn/T/ipykernel_6319/592914679.py:4: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the numbers are always stored in consecutive memory\n",
    "# tensor.view() only changes the view of the memory\n",
    "# No memory is copied, moved, or changed\n",
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80f5f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1067, -0.3255, -0.1067, -0.3255, -0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255,  0.7099, -1.3830],\n",
       "        [-0.1067, -0.3255,  0.7099, -1.3830, -0.2009, -0.5896],\n",
       "        [ 0.7099, -1.3830, -0.2009, -0.5896, -0.2009, -0.5896],\n",
       "        [-0.2009, -0.5896, -0.2009, -0.5896,  0.3376,  0.3419],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255, -0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255,  0.6248,  0.4970],\n",
       "        [-0.1067, -0.3255,  0.6248,  0.4970,  0.8947,  0.9249],\n",
       "        [ 0.6248,  0.4970,  0.8947,  0.9249,  0.6895,  0.9553],\n",
       "        [ 0.8947,  0.9249,  0.6895,  0.9553, -0.3390,  1.2435],\n",
       "        [ 0.6895,  0.9553, -0.3390,  1.2435,  0.6895,  0.9553],\n",
       "        [-0.3390,  1.2435,  0.6895,  0.9553,  0.3376,  0.3419],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255, -0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255,  0.3376,  0.3419],\n",
       "        [-0.1067, -0.3255,  0.3376,  0.3419, -0.3390,  1.2435],\n",
       "        [ 0.3376,  0.3419, -0.3390,  1.2435,  0.3376,  0.3419],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255, -0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255,  0.6895,  0.9553],\n",
       "        [-0.1067, -0.3255,  0.6895,  0.9553, -0.4805,  0.5944],\n",
       "        [ 0.6895,  0.9553, -0.4805,  0.5944,  0.3376,  0.3419],\n",
       "        [-0.4805,  0.5944,  0.3376,  0.3419,  0.1550, -1.1830],\n",
       "        [ 0.3376,  0.3419,  0.1550, -1.1830,  0.7099, -1.3830],\n",
       "        [ 0.1550, -1.1830,  0.7099, -1.3830,  0.8947,  0.9249],\n",
       "        [ 0.7099, -1.3830,  0.8947,  0.9249,  0.8947,  0.9249],\n",
       "        [ 0.8947,  0.9249,  0.8947,  0.9249,  0.3376,  0.3419],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255, -0.1067, -0.3255],\n",
       "        [-0.1067, -0.3255, -0.1067, -0.3255, -0.4805,  0.5944],\n",
       "        [-0.1067, -0.3255, -0.4805,  0.5944,  0.6248,  0.4970],\n",
       "        [-0.4805,  0.5944,  0.6248,  0.4970, -0.6143,  0.1434],\n",
       "        [ 0.6248,  0.4970, -0.6143,  0.1434,  0.1998,  0.2748],\n",
       "        [-0.6143,  0.1434,  0.1998,  0.2748,  0.6895,  0.9553],\n",
       "        [ 0.1998,  0.2748,  0.6895,  0.9553,  0.3376,  0.3419]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we can call view() on our input/embedding to do the same concatenation as before\n",
    "# but much more efficiently\n",
    "emb.view(32, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31348f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are equal operations\n",
    "emb.view(32,6) == torch.cat(torch.unbind(emb, dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c7d9e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3ace01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "924ca300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "097d4e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1273,  1.2489, -0.9927,  ...,  0.2371,  0.3973,  1.9040],\n",
       "        [ 4.0179,  2.2308, -0.1354,  ..., -0.7418,  1.6091,  1.5000],\n",
       "        [ 2.8780,  0.0130, -1.5041,  ..., -0.7511,  1.6324,  2.4067],\n",
       "        ...,\n",
       "        [-1.5841,  2.7658, -0.9163,  ...,  0.3088, -0.2343,  4.0642],\n",
       "        [-1.0090,  1.5656,  1.4986,  ...,  2.0962,  0.5058, -0.4029],\n",
       "        [-0.3640,  1.1712,  0.8459,  ...,  0.4099,  0.4293,  1.6749]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can do the matrix multiplication to get our hidden layer\n",
    "# We can also do  emb.view(-1,6) and PyTorch will derive what that value should be\n",
    "h = emb.view(emb.shape[0],6) @ W1 + b1\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c849a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "502cf0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1266,  0.8480, -0.7585,  ...,  0.2327,  0.3776,  0.9566],\n",
       "        [ 0.9994,  0.9772, -0.1346,  ..., -0.6303,  0.9230,  0.9051],\n",
       "        [ 0.9937,  0.0130, -0.9059,  ..., -0.6358,  0.9264,  0.9839],\n",
       "        ...,\n",
       "        [-0.9192,  0.9921, -0.7242,  ...,  0.2993, -0.2301,  0.9994],\n",
       "        [-0.7654,  0.9163,  0.9049,  ...,  0.9702,  0.4666, -0.3825],\n",
       "        [-0.3487,  0.8247,  0.6889,  ...,  0.3884,  0.4047,  0.9322]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We apply a tanh so that the values are between -1 and 1\n",
    "# Each example gets a tanh applied to it\n",
    "h = torch.tanh(h)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "787a2172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall that we arbitrarily chose 100 nodes for the hidden layer\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6091f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should always double-check that the broadcasting that occurs\n",
    "# when the bias `b` is added is correct\n",
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d925f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c52e94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6, 100 <-- W1\n",
    "# 1, 100 <-- b1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6740a",
   "metadata": {},
   "source": [
    "## Constructing the Final Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2e119ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W1 is a [6,100], meaning it has 100 outputs\n",
    "# So W2 must take in 100 outputs as inputs, and return 27 possible values\n",
    "# (since we have 27 possible characters)\n",
    "W2 = torch.rand((100, 27))\n",
    "b2 = torch.rand(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53573522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `logits` are the outputs of this neural net\n",
    "# Recall h = tanh(emb @ W1 + b1), where `emb` contains the inputs\n",
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1901e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each input example (32 total), the output can be one of 27 values\n",
    "# (a value is generated for each of the 27 characters)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "436289c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the logits to get \"fake counts\"\n",
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46b6ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then normalize the counts to get a probability\n",
    "# dim=1 because that is the final output\n",
    "probs = counts / counts.sum(dim=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "912db445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb4e8339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2830e-02, 2.6477e-03, 2.5297e-02, 7.1397e-04, 2.3385e-02, 5.9174e-04,\n",
       "         2.5189e-03, 1.9391e-02, 4.1260e-02, 7.0951e-02, 2.8402e-02, 5.5036e-03,\n",
       "         3.3958e-03, 2.6606e-02, 1.3090e-02, 2.2776e-02, 2.6900e-03, 1.5114e-04,\n",
       "         2.8795e-03, 3.9758e-03, 1.4960e-01, 3.4082e-01, 1.1522e-01, 5.4229e-02,\n",
       "         7.4304e-03, 3.0238e-03, 6.2127e-04],\n",
       "        [7.0526e-04, 1.5738e-04, 3.8278e-03, 1.3625e-02, 3.0200e-02, 2.9946e-03,\n",
       "         2.9349e-02, 1.5566e-02, 2.3605e-02, 3.9144e-03, 8.7515e-03, 2.8959e-02,\n",
       "         1.1130e-02, 2.3665e-03, 2.5662e-02, 1.8296e-01, 6.2588e-03, 4.6235e-04,\n",
       "         2.4473e-03, 2.4237e-01, 1.2478e-02, 2.8679e-02, 6.9121e-02, 2.2280e-01,\n",
       "         4.8036e-03, 2.4091e-02, 2.7105e-03],\n",
       "        [1.0336e-02, 2.3779e-04, 4.5990e-04, 1.8581e-03, 2.0557e-01, 3.7531e-04,\n",
       "         1.6629e-03, 7.5845e-04, 1.9920e-03, 1.4704e-04, 4.5243e-02, 7.5215e-04,\n",
       "         1.2404e-03, 4.2718e-03, 1.1525e-02, 1.4547e-02, 1.1825e-03, 1.6374e-05,\n",
       "         1.1558e-03, 3.2318e-02, 3.6328e-03, 6.0318e-01, 1.6487e-02, 4.5635e-03,\n",
       "         4.0085e-03, 2.6638e-02, 5.8424e-03],\n",
       "        [9.4744e-02, 1.6732e-03, 2.4906e-02, 1.2443e-03, 2.6437e-02, 6.8270e-04,\n",
       "         8.9878e-04, 9.3504e-02, 2.0771e-03, 7.8265e-03, 2.3097e-03, 2.4489e-02,\n",
       "         3.0443e-02, 2.5754e-03, 8.4769e-02, 1.6488e-01, 7.1904e-02, 3.6366e-03,\n",
       "         5.7776e-03, 1.4201e-02, 1.7034e-02, 8.4219e-02, 1.4721e-01, 1.4201e-02,\n",
       "         6.5273e-02, 1.3051e-02, 3.1351e-05],\n",
       "        [7.7971e-03, 6.4785e-03, 4.3079e-02, 1.4262e-03, 1.1672e-02, 1.9713e-03,\n",
       "         8.4840e-03, 1.4079e-03, 7.4914e-02, 9.7256e-03, 4.6432e-02, 3.7523e-03,\n",
       "         1.4807e-03, 1.2851e-01, 1.4747e-02, 3.4312e-03, 3.0095e-02, 4.6605e-04,\n",
       "         7.7673e-03, 1.4459e-02, 1.2459e-01, 3.2869e-01, 7.1287e-03, 8.6921e-02,\n",
       "         3.2079e-02, 2.2069e-03, 2.9043e-04],\n",
       "        [3.2830e-02, 2.6477e-03, 2.5297e-02, 7.1397e-04, 2.3385e-02, 5.9174e-04,\n",
       "         2.5189e-03, 1.9391e-02, 4.1260e-02, 7.0951e-02, 2.8402e-02, 5.5036e-03,\n",
       "         3.3958e-03, 2.6606e-02, 1.3090e-02, 2.2776e-02, 2.6900e-03, 1.5114e-04,\n",
       "         2.8795e-03, 3.9758e-03, 1.4960e-01, 3.4082e-01, 1.1522e-01, 5.4229e-02,\n",
       "         7.4304e-03, 3.0238e-03, 6.2127e-04],\n",
       "        [1.9990e-03, 9.3912e-03, 2.3943e-02, 3.8806e-03, 7.5435e-03, 5.0642e-03,\n",
       "         1.3346e-02, 2.2792e-03, 5.8745e-02, 5.0327e-02, 1.0343e-01, 1.6172e-02,\n",
       "         2.1806e-03, 1.0316e-01, 4.6826e-03, 7.1930e-03, 2.2581e-02, 1.4330e-03,\n",
       "         1.7023e-02, 2.1093e-02, 1.3249e-01, 1.7407e-01, 2.8600e-02, 1.7419e-01,\n",
       "         7.4335e-03, 7.2136e-03, 5.3503e-04],\n",
       "        [1.6158e-03, 5.3081e-03, 2.1303e-03, 3.3306e-03, 1.2521e-02, 1.0003e-01,\n",
       "         3.0611e-02, 3.2773e-03, 1.5197e-02, 4.2491e-01, 3.7241e-02, 4.5541e-02,\n",
       "         5.8312e-03, 1.0820e-02, 5.2094e-03, 3.0059e-03, 6.7267e-03, 1.0962e-03,\n",
       "         2.1955e-03, 4.4896e-02, 3.4475e-02, 5.6006e-02, 1.2455e-01, 1.7645e-02,\n",
       "         1.0139e-03, 8.2095e-04, 3.9919e-03],\n",
       "        [2.4142e-04, 2.3087e-01, 1.5030e-03, 3.2853e-03, 4.8263e-03, 9.6207e-03,\n",
       "         1.2026e-03, 6.2524e-03, 2.5630e-04, 6.4130e-01, 7.4160e-03, 9.4645e-03,\n",
       "         1.9655e-03, 2.7032e-04, 4.9845e-04, 4.1372e-04, 4.6930e-03, 3.6978e-03,\n",
       "         4.3883e-04, 1.6910e-02, 2.4332e-03, 1.3657e-02, 2.4570e-02, 9.7705e-03,\n",
       "         9.0078e-05, 5.4956e-04, 3.8046e-03],\n",
       "        [2.4936e-04, 2.5874e-01, 1.3632e-03, 1.7859e-04, 7.3216e-05, 1.2002e-03,\n",
       "         3.2271e-05, 1.6076e-02, 4.7867e-04, 6.6700e-01, 2.6037e-02, 7.7499e-04,\n",
       "         1.3535e-03, 4.0524e-05, 1.4503e-05, 8.0081e-05, 6.9873e-04, 2.5148e-03,\n",
       "         1.4874e-03, 9.8830e-05, 1.0710e-03, 1.1429e-03, 2.8204e-03, 1.3738e-02,\n",
       "         1.5274e-05, 1.2407e-04, 2.6039e-03],\n",
       "        [4.3074e-04, 4.8058e-01, 2.1188e-03, 4.7339e-03, 3.3604e-04, 1.2566e-03,\n",
       "         8.3154e-04, 1.1569e-02, 3.0605e-04, 1.2690e-01, 3.6582e-02, 6.4822e-03,\n",
       "         1.0893e-03, 2.5569e-03, 4.4903e-04, 4.1111e-04, 6.6558e-03, 6.4841e-03,\n",
       "         1.9271e-02, 9.1129e-03, 1.7354e-02, 1.1439e-02, 6.6810e-03, 2.4051e-01,\n",
       "         2.8803e-04, 2.8808e-03, 2.6903e-03],\n",
       "        [2.5227e-04, 2.2817e-02, 4.4135e-04, 1.1522e-03, 9.1483e-03, 1.0109e-03,\n",
       "         3.1255e-03, 6.7263e-04, 1.3182e-02, 5.3835e-01, 4.9422e-02, 3.6069e-03,\n",
       "         1.5326e-02, 9.9288e-04, 2.0983e-04, 1.0065e-03, 9.1733e-04, 3.2894e-03,\n",
       "         9.4708e-04, 2.5420e-02, 3.2685e-02, 9.7513e-03, 1.2229e-02, 1.1693e-01,\n",
       "         2.8538e-05, 3.0660e-03, 1.3403e-01],\n",
       "        [3.2830e-02, 2.6477e-03, 2.5297e-02, 7.1397e-04, 2.3385e-02, 5.9174e-04,\n",
       "         2.5189e-03, 1.9391e-02, 4.1260e-02, 7.0951e-02, 2.8402e-02, 5.5036e-03,\n",
       "         3.3958e-03, 2.6606e-02, 1.3090e-02, 2.2776e-02, 2.6900e-03, 1.5114e-04,\n",
       "         2.8795e-03, 3.9758e-03, 1.4960e-01, 3.4082e-01, 1.1522e-01, 5.4229e-02,\n",
       "         7.4304e-03, 3.0238e-03, 6.2127e-04],\n",
       "        [4.4021e-03, 8.9728e-03, 3.0823e-02, 1.8943e-03, 9.2681e-03, 2.2942e-03,\n",
       "         5.7655e-03, 3.1245e-03, 6.2434e-02, 5.1665e-02, 5.2389e-02, 6.4965e-03,\n",
       "         1.8190e-03, 6.8100e-02, 6.5885e-03, 4.7726e-03, 1.3491e-02, 4.8472e-04,\n",
       "         1.1335e-02, 9.7799e-03, 1.6796e-01, 3.1722e-01, 2.6446e-02, 1.1840e-01,\n",
       "         1.0272e-02, 3.3982e-03, 4.0189e-04],\n",
       "        [6.0223e-04, 6.9888e-03, 1.4210e-03, 1.6809e-04, 9.5823e-05, 3.2754e-03,\n",
       "         5.0627e-04, 1.4294e-03, 5.3416e-03, 8.6962e-01, 8.8366e-03, 6.3580e-04,\n",
       "         2.2403e-03, 1.1003e-02, 1.6140e-03, 1.7490e-04, 1.4071e-03, 8.3311e-05,\n",
       "         7.0944e-03, 6.9154e-05, 3.7859e-02, 1.9937e-02, 1.7110e-03, 1.4889e-02,\n",
       "         1.0638e-03, 4.6214e-05, 1.8838e-03],\n",
       "        [5.0306e-04, 1.1914e-01, 2.4741e-03, 1.9426e-04, 1.3595e-05, 3.6564e-04,\n",
       "         1.3936e-04, 1.6037e-02, 6.6173e-04, 6.3516e-01, 6.2986e-04, 2.9732e-03,\n",
       "         5.5204e-04, 4.4919e-03, 4.0971e-04, 8.4686e-04, 3.1715e-04, 1.3003e-03,\n",
       "         2.3615e-03, 4.7459e-04, 1.0849e-01, 2.8305e-03, 2.4084e-02, 7.5315e-02,\n",
       "         3.0406e-05, 9.3306e-05, 1.0517e-04],\n",
       "        [3.2830e-02, 2.6477e-03, 2.5297e-02, 7.1397e-04, 2.3385e-02, 5.9174e-04,\n",
       "         2.5189e-03, 1.9391e-02, 4.1260e-02, 7.0951e-02, 2.8402e-02, 5.5036e-03,\n",
       "         3.3958e-03, 2.6606e-02, 1.3090e-02, 2.2776e-02, 2.6900e-03, 1.5114e-04,\n",
       "         2.8795e-03, 3.9758e-03, 1.4960e-01, 3.4082e-01, 1.1522e-01, 5.4229e-02,\n",
       "         7.4304e-03, 3.0238e-03, 6.2127e-04],\n",
       "        [1.6730e-03, 2.6493e-02, 3.1034e-02, 1.9018e-03, 2.8641e-03, 1.3452e-02,\n",
       "         1.4468e-02, 1.5785e-03, 5.9577e-02, 7.5126e-02, 9.5906e-02, 1.2133e-02,\n",
       "         1.4925e-03, 1.0651e-01, 5.6677e-03, 3.2737e-03, 3.5336e-02, 1.9259e-03,\n",
       "         3.7111e-02, 1.1265e-02, 1.3852e-01, 1.5283e-01, 2.2478e-02, 1.3605e-01,\n",
       "         4.3317e-03, 6.0540e-03, 9.5509e-04],\n",
       "        [2.8720e-04, 4.3044e-03, 7.2005e-04, 3.1070e-05, 1.0094e-04, 3.3564e-04,\n",
       "         2.1080e-04, 3.4191e-03, 1.1971e-03, 9.5517e-01, 4.0579e-03, 2.3815e-04,\n",
       "         5.9369e-03, 8.7325e-04, 1.9569e-04, 3.5241e-04, 3.2483e-04, 4.1479e-05,\n",
       "         3.2394e-04, 9.2935e-05, 9.5717e-03, 8.3955e-03, 7.0486e-04, 2.3165e-03,\n",
       "         1.3848e-04, 9.4654e-06, 6.4947e-04],\n",
       "        [5.5853e-04, 3.5644e-01, 5.1735e-03, 4.1799e-03, 8.8033e-04, 4.9915e-04,\n",
       "         1.2542e-03, 5.0246e-02, 6.9140e-04, 1.3057e-01, 2.1951e-02, 2.3851e-03,\n",
       "         1.9557e-03, 7.4511e-03, 9.1527e-04, 4.2824e-03, 2.9620e-03, 4.6475e-03,\n",
       "         2.9462e-02, 3.3429e-03, 9.0735e-02, 1.6389e-02, 2.0890e-02, 2.3325e-01,\n",
       "         4.6330e-04, 6.1498e-03, 2.2743e-03],\n",
       "        [7.9798e-04, 4.5615e-04, 6.8801e-04, 5.3418e-03, 2.1997e-02, 1.8809e-04,\n",
       "         1.3045e-03, 9.9733e-02, 1.3690e-02, 1.7360e-01, 2.3822e-02, 2.3907e-03,\n",
       "         3.3951e-02, 1.5498e-03, 2.9448e-03, 1.5174e-02, 4.6625e-05, 3.2463e-04,\n",
       "         1.0082e-03, 4.0483e-02, 2.6757e-02, 2.1445e-02, 1.9268e-01, 2.9457e-01,\n",
       "         4.1113e-05, 2.8319e-03, 2.2194e-02],\n",
       "        [1.2113e-04, 2.3147e-04, 3.8715e-04, 3.7566e-02, 3.6049e-02, 9.7527e-04,\n",
       "         1.0935e-02, 3.3210e-03, 4.0150e-03, 1.8687e-04, 1.6870e-02, 1.2489e-03,\n",
       "         8.8046e-03, 6.0297e-04, 3.2241e-02, 1.1100e-01, 9.6117e-03, 2.3692e-04,\n",
       "         3.0292e-03, 1.7369e-01, 8.8905e-03, 9.9210e-03, 1.8828e-01, 1.0935e-01,\n",
       "         1.2257e-02, 1.9073e-01, 2.9455e-02],\n",
       "        [7.4766e-03, 1.0988e-03, 9.7562e-04, 5.9665e-03, 1.1893e-01, 2.8219e-03,\n",
       "         1.4697e-02, 8.2278e-05, 3.5982e-03, 1.4986e-04, 4.4376e-02, 2.8484e-03,\n",
       "         2.3793e-04, 1.0386e-02, 5.9507e-03, 1.2041e-03, 1.1569e-01, 1.5571e-04,\n",
       "         1.2471e-02, 2.0393e-01, 2.6378e-03, 3.2365e-01, 2.5524e-03, 6.3051e-03,\n",
       "         1.0368e-01, 6.5871e-03, 1.5414e-03],\n",
       "        [1.6246e-03, 3.2037e-02, 2.5247e-02, 2.1283e-02, 3.6580e-03, 1.7305e-02,\n",
       "         7.6398e-03, 2.7691e-02, 2.2789e-03, 6.3787e-01, 2.6175e-03, 6.8627e-02,\n",
       "         2.2893e-02, 1.7839e-03, 2.3955e-03, 7.3678e-03, 8.8989e-03, 2.7347e-03,\n",
       "         3.2839e-04, 2.4335e-02, 7.6718e-03, 1.2810e-03, 7.0521e-02, 1.2904e-03,\n",
       "         4.7856e-04, 6.4350e-05, 7.9399e-05],\n",
       "        [3.6939e-04, 1.5407e-01, 1.1695e-03, 5.9807e-03, 1.5496e-02, 2.6000e-03,\n",
       "         4.6584e-04, 4.3190e-02, 2.2804e-04, 4.3680e-01, 2.6751e-02, 5.4710e-03,\n",
       "         1.7028e-02, 1.3319e-04, 4.4572e-04, 1.5072e-03, 1.1326e-03, 8.8236e-03,\n",
       "         9.1619e-04, 8.1565e-02, 4.8927e-03, 1.3547e-02, 1.1136e-01, 3.3002e-02,\n",
       "         9.6888e-05, 1.7158e-03, 3.1231e-02],\n",
       "        [3.2830e-02, 2.6477e-03, 2.5297e-02, 7.1397e-04, 2.3385e-02, 5.9174e-04,\n",
       "         2.5189e-03, 1.9391e-02, 4.1260e-02, 7.0951e-02, 2.8402e-02, 5.5036e-03,\n",
       "         3.3958e-03, 2.6606e-02, 1.3090e-02, 2.2776e-02, 2.6900e-03, 1.5114e-04,\n",
       "         2.8795e-03, 3.9758e-03, 1.4960e-01, 3.4082e-01, 1.1522e-01, 5.4229e-02,\n",
       "         7.4304e-03, 3.0238e-03, 6.2127e-04],\n",
       "        [8.4880e-03, 1.7037e-02, 1.6810e-02, 5.0998e-04, 2.0960e-03, 1.1796e-03,\n",
       "         3.4188e-04, 7.1501e-03, 2.8351e-02, 2.9817e-01, 7.0790e-03, 9.6395e-04,\n",
       "         4.7285e-03, 5.6438e-02, 6.8872e-03, 1.9754e-03, 3.8918e-03, 1.9025e-04,\n",
       "         1.8751e-02, 2.0588e-04, 1.7624e-01, 2.9646e-01, 4.0997e-03, 3.0105e-02,\n",
       "         1.0864e-02, 5.3369e-04, 4.4888e-04],\n",
       "        [1.8512e-03, 1.1882e-02, 1.8166e-02, 1.0880e-03, 9.3584e-05, 3.4971e-03,\n",
       "         2.4542e-03, 4.7015e-03, 3.3199e-02, 2.4990e-01, 8.0606e-03, 1.5152e-02,\n",
       "         1.4947e-03, 7.3729e-02, 4.0413e-03, 5.3768e-03, 9.6106e-04, 5.8420e-03,\n",
       "         1.1023e-02, 1.1099e-02, 3.9499e-01, 1.3247e-02, 5.1586e-02, 7.4753e-02,\n",
       "         8.9819e-04, 5.9480e-04, 3.1178e-04],\n",
       "        [4.9092e-04, 9.0288e-04, 3.7635e-04, 2.0111e-05, 1.0289e-03, 6.2571e-05,\n",
       "         1.2835e-04, 9.6600e-04, 9.4357e-03, 9.1725e-01, 1.0074e-02, 1.0441e-04,\n",
       "         5.0119e-03, 9.6768e-04, 3.1419e-04, 7.0520e-04, 8.4512e-05, 4.4775e-05,\n",
       "         3.0525e-04, 3.5145e-04, 1.2633e-02, 1.4198e-02, 1.3549e-03, 1.1413e-02,\n",
       "         4.6045e-05, 1.1000e-04, 1.1621e-02],\n",
       "        [3.0380e-03, 7.7262e-02, 1.7375e-02, 4.7711e-03, 7.8153e-04, 8.6702e-04,\n",
       "         2.7376e-03, 4.8462e-02, 2.7318e-03, 1.9646e-01, 1.5328e-02, 5.0310e-03,\n",
       "         2.3998e-03, 1.3856e-02, 1.7930e-03, 1.9080e-02, 3.4584e-03, 1.6792e-03,\n",
       "         5.2367e-02, 1.8531e-03, 1.2222e-01, 2.7108e-02, 6.6348e-02, 3.0216e-01,\n",
       "         6.8388e-04, 9.4489e-03, 7.0209e-04],\n",
       "        [4.1721e-04, 2.6564e-03, 1.9740e-03, 6.6156e-04, 3.9660e-03, 3.2106e-02,\n",
       "         4.5936e-02, 3.5013e-04, 1.5421e-01, 1.6973e-01, 6.4177e-02, 2.1577e-02,\n",
       "         1.7489e-03, 1.3753e-02, 4.3952e-03, 1.1333e-03, 2.1697e-03, 7.5712e-04,\n",
       "         1.0714e-02, 1.0340e-02, 1.8184e-01, 1.1150e-01, 4.3031e-02, 8.8805e-02,\n",
       "         8.6418e-04, 1.5072e-03, 2.9670e-02],\n",
       "        [1.4407e-04, 1.5507e-02, 6.3059e-04, 2.1151e-04, 8.4392e-04, 9.1435e-04,\n",
       "         3.4332e-04, 3.5580e-03, 9.1988e-04, 9.1671e-01, 4.1272e-03, 2.9015e-03,\n",
       "         2.9614e-03, 1.9346e-04, 8.2882e-05, 3.1867e-04, 2.7651e-04, 4.5666e-04,\n",
       "         7.7455e-05, 4.5155e-03, 9.2042e-03, 5.1423e-03, 2.2820e-02, 5.6734e-03,\n",
       "         1.8556e-05, 6.0558e-05, 1.3901e-03]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25caff9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each row in probs now sum to 1\n",
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6392830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The correct answer of the next character is provided by Y\n",
    "# So for each row in probs, we need to get the probability that was generated for the output character\n",
    "# of each example (a row in probs)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51b82fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a list of indices to index into probs\n",
    "# We want to index into each example (32 examples total)\n",
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a43166b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.9174e-04, 2.3665e-03, 4.2718e-03, 1.6732e-03, 7.7971e-03, 2.2776e-02,\n",
       "        2.1806e-03, 4.2491e-01, 2.4570e-02, 6.6700e-01, 4.8058e-01, 2.5227e-04,\n",
       "        2.6477e-03, 2.6446e-02, 6.9888e-03, 5.0306e-04, 7.0951e-02, 1.1265e-02,\n",
       "        4.3044e-03, 5.1735e-03, 1.8809e-04, 8.8046e-03, 2.3793e-04, 3.2037e-02,\n",
       "        3.6939e-04, 3.9758e-03, 1.9754e-03, 9.6106e-04, 9.4357e-03, 1.9646e-01,\n",
       "        2.6564e-03, 1.4407e-04])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then use Y as a list of indicies\n",
    "# This automatically grabs the probabiltiy assigned to each output character in Y, for each example\n",
    "probs[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e6ae87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ideal goal of training is to get all the probabilities of each correct character per example is 1 (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc97775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2129)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we calculate the negative log liklihood for loss\n",
    "# This is the loss we'd like to minimize\n",
    "loss = -probs[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e8b9b",
   "metadata": {},
   "source": [
    "## Complete Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5182e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3d1d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c26b52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 characters, each character has an embedding/representation of two floats\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# 3 characters per input, 2 embeddings per character\n",
    "# 100 is an arbitrary number of nodes\n",
    "W1 = torch.randn((6,100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "\n",
    "# 100 inputs from previous layer, 27 possible characters as outputs\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1a2c143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of parameters in total\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5252d248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to calculate the loss\n",
    "# More efficient forward and backward pass, and handles extreme values in logits\n",
    "# Examples, large numbers exponentiated (logits.exp()) can lead to infinity as a value\n",
    "#     PyTorch would handle that case\n",
    "F.cross_entropy(logits, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e364e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the gradients\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2207390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 loss: 17.76971435546875\n",
      "Iteration 100 loss: 0.3354485332965851\n",
      "Iteration 200 loss: 0.2789476215839386\n",
      "Iteration 300 loss: 0.2678886950016022\n",
      "Iteration 400 loss: 0.26317593455314636\n",
      "Iteration 500 loss: 0.2638612389564514\n",
      "Iteration 600 loss: 0.26023462414741516\n",
      "Iteration 700 loss: 0.2586209177970886\n",
      "Iteration 800 loss: 0.25756219029426575\n",
      "Iteration 900 loss: 0.2567654848098755\n"
     ]
    }
   ],
   "source": [
    "for iter in range(1000):\n",
    "    # Forward Pass\n",
    "\n",
    "    # Embeddings of all the characters in the input X\n",
    "    emb = C[X] # shape: (32, block_size, 2)\n",
    "    # Hidden layer\n",
    "    # We get the embedding to a shape that is compatible with the W1 matrix\n",
    "    # Activations for each of our 32 examples\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # shape: (32, 100)\n",
    "    # Get the results for each example (a probability distribution across the possible next character)\n",
    "    logits = h @ W2 + b2 # Shape: (32, 27)\n",
    "    # counts = logits.exp()\n",
    "    # Create a probability distribution\n",
    "    # Each row in prob sum to 1.0\n",
    "    # prob = counts / counts.sum(1, keepdims=True)\n",
    "    # Get the probability of the actual next character (given by Y)\n",
    "    # The goal of training is to get the probability of the correct character close to 1.0\n",
    "    # Negative log likelihood loss\n",
    "    # loss = -prob[torch.arange(32), Y].log().mean()\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "\n",
    "    # Backward Pass\n",
    "\n",
    "    # Reset the gradients\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # Calculate the gradients    \n",
    "    loss.backward()\n",
    "    if iter%100 == 0:\n",
    "        print(f\"Iteration {iter} loss: {loss.item()}\")\n",
    "    \n",
    "    # Update\n",
    "    learning_rate = 0.1\n",
    "    for p in parameters:\n",
    "        # Nudge the weights in the direction of the gradient\n",
    "        # Negate since we are trying to minimize the loss\n",
    "        p.data += -learning_rate * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b6dcf",
   "metadata": {},
   "source": [
    "The loss is decreasing easily because we are overfitting. We have over 3k parameters for just 32 examples.\n",
    "We can't get loss completely to zero because there are examples where the next character could be from a possible set of characters (ex. \"...\" can be followed by either \"e\" (emma), \"o\" (olivia), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531d0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
