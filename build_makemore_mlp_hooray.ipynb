{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b908cb-2c1d-4c2b-84b2-ea18867ea87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f35433-59bd-4577-bb93-03eca7539002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in all the names, as a list of names\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d40047ee-fc04-4e80-a573-19052e8ae9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(words)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5213b782-cce5-4d0a-a3ab-50b29a3d8446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build character to integer mapping\n",
    "# First we combine all the names into one string, then create a set() (this keeps unique characters only)\n",
    "# Then we sort alphabetically\n",
    "chars = sorted(set(\"\".join(words)))\n",
    "\n",
    "# String to integer\n",
    "stoi = {c:i+1 for (i, c) in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e9349-6c01-4bc3-889f-733804ea339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer to string\n",
    "itos = {i:c for (c,i) in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3345086",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb5b5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# Context length: how many previous characters do we use to predict the next character\n",
    "block_size = 3\n",
    "\n",
    "# Inputs to the neural net (the previous characters seen)\n",
    "X = []\n",
    "# The labels of the inputs to the neural net (the next character)\n",
    "Y = []\n",
    "\n",
    "# Create a dataset, mapping `block_size` characters -> next character\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    \n",
    "    # Initialize the context with empty characters\n",
    "    context = [stoi[\".\"]] * block_size\n",
    "    # We want the last characters of the name to be included in the dataset\n",
    "    # which is why we append \".\" to the end of the name\n",
    "    for w in word + \".\":\n",
    "        # Get the next character\n",
    "        ix = stoi[w]\n",
    "        \n",
    "        # Save the input and output\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "            \n",
    "        # Print the example\n",
    "        print(\"\".join(itos[i] for i in context) + \" ---> \" + itos[ix])\n",
    "        \n",
    "        # Remove the earliest character in the context, and append the newest character\n",
    "        # as the latest character in the context\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "# Inputs\n",
    "X = torch.tensor(X)\n",
    "# Labels\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ed7c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 3]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# We have x many input examples, with each with a context size `block_size`\n",
    "print(f\"Input shape: {X.shape}, {X.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d7531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([32]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# The next character is one of 27 possible characters\n",
    "print(f\"Labels shape: {Y.shape}, {Y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e14a4",
   "metadata": {},
   "source": [
    "## Building the Embedding Table `C`\n",
    "In the paper, 17,000 possible words are crammed into a 30-dimensional space.\n",
    "We have 27 possible characters, so let's cram them into a 2-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "706c9aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0088, -1.1016],\n",
       "        [ 0.7970, -0.3561],\n",
       "        [-0.3655, -0.4275],\n",
       "        [-1.1269, -0.0039],\n",
       "        [ 0.0813, -1.8065],\n",
       "        [-0.2585,  0.4642],\n",
       "        [-1.1480, -1.4260],\n",
       "        [-0.4930,  0.7735],\n",
       "        [ 0.3500,  0.9715],\n",
       "        [-0.9872,  0.2489],\n",
       "        [ 0.0348,  0.7573],\n",
       "        [ 0.0066,  0.3187],\n",
       "        [-2.2436,  0.7938],\n",
       "        [ 0.5505,  1.3333],\n",
       "        [ 0.5966,  0.5793],\n",
       "        [ 0.3108, -0.8955],\n",
       "        [-0.7096, -0.2041],\n",
       "        [-0.2271,  1.7375],\n",
       "        [ 0.4156,  1.4305],\n",
       "        [-0.4538, -0.0266],\n",
       "        [-1.8510,  0.7650],\n",
       "        [ 0.4639, -0.8264],\n",
       "        [-0.8211,  0.0090],\n",
       "        [ 0.6062,  0.6858],\n",
       "        [-2.1856, -1.0730],\n",
       "        [-0.0255,  1.4148],\n",
       "        [-0.1103,  1.1912]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 27 possible characters, 2-dimensional space\n",
    "# Each character has a 2-dimenional embedding\n",
    "C = torch.randn((27, 2))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be366943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character g maps to 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.7620,  0.1511])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 'g'\n",
    "c_index = stoi[c]\n",
    "print(f\"Character {c} maps to {c_index}\")\n",
    "C[c_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24ad2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing into the embedding table `C` is the same as matrix multiplying\n",
    "# `C` with the one-hot encoding representation of the input character\n",
    "v = F.one_hot(torch.tensor(c_index), num_classes=27)\n",
    "v.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11319dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7620,  0.1511])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to cast the vector to a float since the embedding table C contains floats\n",
    "v.float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7679b9",
   "metadata": {},
   "source": [
    "Embedding a single character into the embedding table `C` is easy. Just use the integer representation of that character, and index into `C`. But how do we simultaneously embed `[32,3]` (32 examples, each of size 3, stored in array `X`) into `C`?\n",
    "\n",
    "In addition to integers, we can use lists to index into `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b70c525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3655, -0.4275],\n",
       "        [-1.1269, -0.0039],\n",
       "        [ 0.0813, -1.8065]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets the rows at index 2, 3, and 4\n",
    "C[[2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df1f150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3655, -0.4275],\n",
       "        [-1.1269, -0.0039],\n",
       "        [ 0.0813, -1.8065]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also index using Tensors\n",
    "C[torch.tensor([2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f21f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3655, -0.4275],\n",
       "        [-0.3655, -0.4275],\n",
       "        [-0.3655, -0.4275]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the same row multiple times\n",
    "C[[2,2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a89bbac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall, X contains the characters as integers as input\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf02c925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape torch.Size([32, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [-0.2585,  0.4642]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.2585,  0.4642],\n",
       "         [ 0.5505,  1.3333]],\n",
       "\n",
       "        [[-0.2585,  0.4642],\n",
       "         [ 0.5505,  1.3333],\n",
       "         [ 0.5505,  1.3333]],\n",
       "\n",
       "        [[ 0.5505,  1.3333],\n",
       "         [ 0.5505,  1.3333],\n",
       "         [ 0.7970, -0.3561]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [ 0.3108, -0.8955]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [ 0.3108, -0.8955],\n",
       "         [-2.2436,  0.7938]],\n",
       "\n",
       "        [[ 0.3108, -0.8955],\n",
       "         [-2.2436,  0.7938],\n",
       "         [-0.9872,  0.2489]],\n",
       "\n",
       "        [[-2.2436,  0.7938],\n",
       "         [-0.9872,  0.2489],\n",
       "         [-0.8211,  0.0090]],\n",
       "\n",
       "        [[-0.9872,  0.2489],\n",
       "         [-0.8211,  0.0090],\n",
       "         [-0.9872,  0.2489]],\n",
       "\n",
       "        [[-0.8211,  0.0090],\n",
       "         [-0.9872,  0.2489],\n",
       "         [ 0.7970, -0.3561]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [ 0.7970, -0.3561]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [ 0.7970, -0.3561],\n",
       "         [-0.8211,  0.0090]],\n",
       "\n",
       "        [[ 0.7970, -0.3561],\n",
       "         [-0.8211,  0.0090],\n",
       "         [ 0.7970, -0.3561]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [-0.9872,  0.2489]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.9872,  0.2489],\n",
       "         [-0.4538, -0.0266]],\n",
       "\n",
       "        [[-0.9872,  0.2489],\n",
       "         [-0.4538, -0.0266],\n",
       "         [ 0.7970, -0.3561]],\n",
       "\n",
       "        [[-0.4538, -0.0266],\n",
       "         [ 0.7970, -0.3561],\n",
       "         [-0.3655, -0.4275]],\n",
       "\n",
       "        [[ 0.7970, -0.3561],\n",
       "         [-0.3655, -0.4275],\n",
       "         [-0.2585,  0.4642]],\n",
       "\n",
       "        [[-0.3655, -0.4275],\n",
       "         [-0.2585,  0.4642],\n",
       "         [-2.2436,  0.7938]],\n",
       "\n",
       "        [[-0.2585,  0.4642],\n",
       "         [-2.2436,  0.7938],\n",
       "         [-2.2436,  0.7938]],\n",
       "\n",
       "        [[-2.2436,  0.7938],\n",
       "         [-2.2436,  0.7938],\n",
       "         [ 0.7970, -0.3561]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.0088, -1.1016],\n",
       "         [-0.4538, -0.0266]],\n",
       "\n",
       "        [[-0.0088, -1.1016],\n",
       "         [-0.4538, -0.0266],\n",
       "         [ 0.3108, -0.8955]],\n",
       "\n",
       "        [[-0.4538, -0.0266],\n",
       "         [ 0.3108, -0.8955],\n",
       "         [-0.7096, -0.2041]],\n",
       "\n",
       "        [[ 0.3108, -0.8955],\n",
       "         [-0.7096, -0.2041],\n",
       "         [ 0.3500,  0.9715]],\n",
       "\n",
       "        [[-0.7096, -0.2041],\n",
       "         [ 0.3500,  0.9715],\n",
       "         [-0.9872,  0.2489]],\n",
       "\n",
       "        [[ 0.3500,  0.9715],\n",
       "         [-0.9872,  0.2489],\n",
       "         [ 0.7970, -0.3561]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can index into the embedding table `C` using multi-dimensional tensors too\n",
    "# The character integers in X is used as the indices into C\n",
    "print(\"X.shape\", X.shape)\n",
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "153492e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [32, 3] was the shape of the input X, then each input has an embedding of 2\n",
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d40b09b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 2nd character in the 7th example\n",
    "example_index = 7\n",
    "character_index = 2\n",
    "X[example_index,character_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ac3582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the character representation of the integer\n",
    "itos[X[example_index,character_index].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a11182dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2436,  0.7938])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the *embedding*of the 2nd character in the 7th example\n",
    "C[X][example_index,character_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3943da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2436,  0.7938])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C[12] is equivalent to C[X[7,2]]\n",
    "C[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2de2444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We created our embedding table integrated with our example inputs!\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f5a6d",
   "metadata": {},
   "source": [
    "## Contructing the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4497a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "# 3 characters per input, and each characters has two floats that represent it (it's embedding)\n",
    "# 3*2 = 6 outputs in the first layer\n",
    "# So the hidden layer has to take in 6 inputs\n",
    "# The number of out put nodes is a variable, we arbitrary choose 100 for now\n",
    "W1 = torch.randn((6,100))\n",
    "# Biases, should match the size of the hidden layer\n",
    "b = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3911d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
