{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b908cb-2c1d-4c2b-84b2-ea18867ea87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f35433-59bd-4577-bb93-03eca7539002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in all the names, as a list of names\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d40047ee-fc04-4e80-a573-19052e8ae9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(words)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5213b782-cce5-4d0a-a3ab-50b29a3d8446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build character to integer mapping\n",
    "# First we combine all the names into one string, then create a set() (this keeps unique characters only)\n",
    "# Then we sort alphabetically\n",
    "chars = sorted(set(\"\".join(words)))\n",
    "\n",
    "# String to integer\n",
    "stoi = {c:i+1 for (i, c) in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e9349-6c01-4bc3-889f-733804ea339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer to string\n",
    "itos = {i:c for (c,i) in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3345086",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5b5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# Context length: how many previous characters do we use to predict the next character\n",
    "block_size = 3\n",
    "\n",
    "# Inputs to the neural net (the previous characters seen)\n",
    "X = []\n",
    "# The labels of the inputs to the neural net (the next character)\n",
    "Y = []\n",
    "\n",
    "# Create a dataset, mapping `block_size` characters -> next character\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    \n",
    "    # Initialize the context with empty characters\n",
    "    context = [stoi[\".\"]] * block_size\n",
    "    # We want the last characters of the name to be included in the dataset\n",
    "    # which is why we append \".\" to the end of the name\n",
    "    for w in word + \".\":\n",
    "        # Get the next character\n",
    "        ix = stoi[w]\n",
    "        \n",
    "        # Save the input and output\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "            \n",
    "        # Print the example\n",
    "        print(\"\".join(itos[i] for i in context) + \" ---> \" + itos[ix])\n",
    "        \n",
    "        # Remove the earliest character in the context, and append the newest character\n",
    "        # as the latest character in the context\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "# Inputs\n",
    "X = torch.tensor(X)\n",
    "# Labels\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ed7c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 3]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# We have x many input examples, with each with a context size `block_size`\n",
    "print(f\"Input shape: {X.shape}, {X.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6d7531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([32]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# The next character is one of 27 possible characters\n",
    "print(f\"Labels shape: {Y.shape}, {Y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e14a4",
   "metadata": {},
   "source": [
    "## Building the Embedding Table `C`\n",
    "In the paper, 17,000 possible words are crammed into a 30-dimensional space.\n",
    "We have 27 possible characters, so let's cram them into a 2-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706c9aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.2731e-01,  1.4308e+00],\n",
       "        [-3.6150e-01, -6.0263e-01],\n",
       "        [ 1.6107e+00, -4.1672e-02],\n",
       "        [-9.0850e-01, -7.9790e-01],\n",
       "        [ 1.9119e-01, -1.4500e-01],\n",
       "        [-5.9361e-01, -9.5892e-01],\n",
       "        [ 1.0253e-01,  4.1094e-01],\n",
       "        [-6.1766e-01, -4.0082e-01],\n",
       "        [-5.4639e-01,  3.3811e-01],\n",
       "        [ 5.2021e-01,  6.2468e-01],\n",
       "        [ 8.3759e-02, -6.9934e-04],\n",
       "        [ 7.8323e-01,  3.6488e-01],\n",
       "        [-4.6051e-01,  4.7479e-02],\n",
       "        [-2.3226e-01,  9.8454e-01],\n",
       "        [-9.0988e-01,  1.1672e+00],\n",
       "        [-7.4115e-02,  5.3692e-01],\n",
       "        [ 6.8232e-01,  3.2136e-01],\n",
       "        [-2.4315e+00, -2.1637e-01],\n",
       "        [-8.2748e-01, -1.1725e-01],\n",
       "        [-5.4597e-01, -2.4455e+00],\n",
       "        [-1.0707e+00,  1.9573e-01],\n",
       "        [-1.6855e+00,  1.1341e+00],\n",
       "        [-1.8326e+00,  5.5144e-01],\n",
       "        [-7.0988e-01,  5.1479e-01],\n",
       "        [-1.0982e+00,  7.6035e-01],\n",
       "        [ 2.0533e+00, -3.2587e-01],\n",
       "        [ 6.2168e-01,  8.6846e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 27 possible characters, 2-dimensional space\n",
    "# Each character has a 2-dimenional embedding\n",
    "C = torch.randn((27, 2))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be366943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character g maps to 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.6177, -0.4008])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 'g'\n",
    "c_index = stoi[c]\n",
    "print(f\"Character {c} maps to {c_index}\")\n",
    "C[c_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ad2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing into the embedding table `C` is the same as matrix multiplying\n",
    "# `C` with the one-hot encoding representation of the input character\n",
    "v = F.one_hot(torch.tensor(c_index), num_classes=27)\n",
    "v.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11319dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6177, -0.4008])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to cast the vector to a float since the embedding table C contains floats\n",
    "v.float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7679b9",
   "metadata": {},
   "source": [
    "Embedding a single character into the embedding table `C` is easy. Just use the integer representation of that character, and index into `C`. But how do we simultaneously embed `[32,3]` (32 examples, each of size 3, stored in array `X`) into `C`?\n",
    "\n",
    "In addition to integers, we can use lists to index into `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b70c525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6107, -0.0417],\n",
       "        [-0.9085, -0.7979],\n",
       "        [ 0.1912, -0.1450]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets the rows at index 2, 3, and 4\n",
    "C[[2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1f150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6107, -0.0417],\n",
       "        [-0.9085, -0.7979],\n",
       "        [ 0.1912, -0.1450]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also index using Tensors\n",
    "C[torch.tensor([2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15f21f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6107, -0.0417],\n",
       "        [ 1.6107, -0.0417],\n",
       "        [ 1.6107, -0.0417]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the same row multiple times\n",
    "C[[2,2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a89bbac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall, X contains the characters as integers as input\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf02c925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape torch.Size([32, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.5936, -0.9589]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.5936, -0.9589],\n",
       "         [-0.2323,  0.9845]],\n",
       "\n",
       "        [[-0.5936, -0.9589],\n",
       "         [-0.2323,  0.9845],\n",
       "         [-0.2323,  0.9845]],\n",
       "\n",
       "        [[-0.2323,  0.9845],\n",
       "         [-0.2323,  0.9845],\n",
       "         [-0.3615, -0.6026]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.0741,  0.5369]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.0741,  0.5369],\n",
       "         [-0.4605,  0.0475]],\n",
       "\n",
       "        [[-0.0741,  0.5369],\n",
       "         [-0.4605,  0.0475],\n",
       "         [ 0.5202,  0.6247]],\n",
       "\n",
       "        [[-0.4605,  0.0475],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-1.8326,  0.5514]],\n",
       "\n",
       "        [[ 0.5202,  0.6247],\n",
       "         [-1.8326,  0.5514],\n",
       "         [ 0.5202,  0.6247]],\n",
       "\n",
       "        [[-1.8326,  0.5514],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.3615, -0.6026]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.3615, -0.6026]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.3615, -0.6026],\n",
       "         [-1.8326,  0.5514]],\n",
       "\n",
       "        [[-0.3615, -0.6026],\n",
       "         [-1.8326,  0.5514],\n",
       "         [-0.3615, -0.6026]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [ 0.5202,  0.6247]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.5460, -2.4455]],\n",
       "\n",
       "        [[ 0.5202,  0.6247],\n",
       "         [-0.5460, -2.4455],\n",
       "         [-0.3615, -0.6026]],\n",
       "\n",
       "        [[-0.5460, -2.4455],\n",
       "         [-0.3615, -0.6026],\n",
       "         [ 1.6107, -0.0417]],\n",
       "\n",
       "        [[-0.3615, -0.6026],\n",
       "         [ 1.6107, -0.0417],\n",
       "         [-0.5936, -0.9589]],\n",
       "\n",
       "        [[ 1.6107, -0.0417],\n",
       "         [-0.5936, -0.9589],\n",
       "         [-0.4605,  0.0475]],\n",
       "\n",
       "        [[-0.5936, -0.9589],\n",
       "         [-0.4605,  0.0475],\n",
       "         [-0.4605,  0.0475]],\n",
       "\n",
       "        [[-0.4605,  0.0475],\n",
       "         [-0.4605,  0.0475],\n",
       "         [-0.3615, -0.6026]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.5460, -2.4455]],\n",
       "\n",
       "        [[-0.9273,  1.4308],\n",
       "         [-0.5460, -2.4455],\n",
       "         [-0.0741,  0.5369]],\n",
       "\n",
       "        [[-0.5460, -2.4455],\n",
       "         [-0.0741,  0.5369],\n",
       "         [ 0.6823,  0.3214]],\n",
       "\n",
       "        [[-0.0741,  0.5369],\n",
       "         [ 0.6823,  0.3214],\n",
       "         [-0.5464,  0.3381]],\n",
       "\n",
       "        [[ 0.6823,  0.3214],\n",
       "         [-0.5464,  0.3381],\n",
       "         [ 0.5202,  0.6247]],\n",
       "\n",
       "        [[-0.5464,  0.3381],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.3615, -0.6026]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can index into the embedding table `C` using multi-dimensional tensors too\n",
    "# The character integers in X is used as the indices into C\n",
    "print(\"X.shape\", X.shape)\n",
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153492e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [32, 3] was the shape of the input X, then each input has an embedding of 2\n",
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d40b09b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 2nd character in the 7th example\n",
    "example_index = 7\n",
    "character_index = 2\n",
    "X[example_index,character_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ac3582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the character representation of the integer\n",
    "itos[X[example_index,character_index].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a11182dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4605,  0.0475])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the *embedding*of the 2nd character in the 7th example\n",
    "C[X][example_index,character_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3943da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4605,  0.0475])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C[12] is equivalent to C[X[7,2]]\n",
    "C[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2de2444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We created our embedding table integrated with our example inputs!\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f5a6d",
   "metadata": {},
   "source": [
    "## Contructing the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4497a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "# 3 characters per input, and each characters has two floats that represent it (it's embedding)\n",
    "# 3*2 = 6 outputs in the first layer\n",
    "# So the hidden layer has to take in 6 inputs\n",
    "# The number of out put nodes is a variable, we arbitrary choose 100 for now\n",
    "W1 = torch.randn((6,100))\n",
    "# Biases, should match the size of the hidden layer\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff3911d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The goal is to be able to do:\n",
    "# emb @ W1 + b\n",
    "# with `@` indicating matrix multiply\n",
    "# and `emb` as our input\n",
    "# We can't do this directly since their shapes don't match correctly\n",
    "# The goal is to get the input/embedding of shape [32,6]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b26ea7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7168f7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.5936, -0.9589],\n",
       "        [-0.2323,  0.9845],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.0741,  0.5369],\n",
       "        [-0.4605,  0.0475],\n",
       "        [ 0.5202,  0.6247],\n",
       "        [-1.8326,  0.5514],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.3615, -0.6026],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [ 0.5202,  0.6247],\n",
       "        [-0.5460, -2.4455],\n",
       "        [-0.3615, -0.6026],\n",
       "        [ 1.6107, -0.0417],\n",
       "        [-0.5936, -0.9589],\n",
       "        [-0.4605,  0.0475],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308],\n",
       "        [-0.5460, -2.4455],\n",
       "        [-0.0741,  0.5369],\n",
       "        [ 0.6823,  0.3214],\n",
       "        [-0.5464,  0.3381]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To do this, we can concatenate the three characters and their embeddings\n",
    "# This grabs all the examples, indexes that into index 0 (first character)\n",
    "# then grabs all the embeddings of the first character for all the examples\n",
    "emb[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70ac1e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets the embeddings of all the first characters in each example\n",
    "emb[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ac67b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to concatenate the embeddings of all the characters\n",
    "# Each emb[:, x, :] has shape [32, 2]\n",
    "# and we want to concatenate cross the dim=1 to get [32,6]\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 1, :]], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15fae181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.5936, -0.9589],\n",
       "         [-0.2323,  0.9845],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.0741,  0.5369],\n",
       "         [-0.4605,  0.0475],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-1.8326,  0.5514],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.3615, -0.6026],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.5460, -2.4455],\n",
       "         [-0.3615, -0.6026],\n",
       "         [ 1.6107, -0.0417],\n",
       "         [-0.5936, -0.9589],\n",
       "         [-0.4605,  0.0475],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.5460, -2.4455],\n",
       "         [-0.0741,  0.5369],\n",
       "         [ 0.6823,  0.3214],\n",
       "         [-0.5464,  0.3381]]),\n",
       " tensor([[-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.5936, -0.9589],\n",
       "         [-0.2323,  0.9845],\n",
       "         [-0.2323,  0.9845],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.0741,  0.5369],\n",
       "         [-0.4605,  0.0475],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-1.8326,  0.5514],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.3615, -0.6026],\n",
       "         [-1.8326,  0.5514],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.5460, -2.4455],\n",
       "         [-0.3615, -0.6026],\n",
       "         [ 1.6107, -0.0417],\n",
       "         [-0.5936, -0.9589],\n",
       "         [-0.4605,  0.0475],\n",
       "         [-0.4605,  0.0475],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.5460, -2.4455],\n",
       "         [-0.0741,  0.5369],\n",
       "         [ 0.6823,  0.3214],\n",
       "         [-0.5464,  0.3381],\n",
       "         [ 0.5202,  0.6247]]),\n",
       " tensor([[-0.9273,  1.4308],\n",
       "         [-0.5936, -0.9589],\n",
       "         [-0.2323,  0.9845],\n",
       "         [-0.2323,  0.9845],\n",
       "         [-0.3615, -0.6026],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.0741,  0.5369],\n",
       "         [-0.4605,  0.0475],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-1.8326,  0.5514],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.3615, -0.6026],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.3615, -0.6026],\n",
       "         [-1.8326,  0.5514],\n",
       "         [-0.3615, -0.6026],\n",
       "         [-0.9273,  1.4308],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.5460, -2.4455],\n",
       "         [-0.3615, -0.6026],\n",
       "         [ 1.6107, -0.0417],\n",
       "         [-0.5936, -0.9589],\n",
       "         [-0.4605,  0.0475],\n",
       "         [-0.4605,  0.0475],\n",
       "         [-0.3615, -0.6026],\n",
       "         [-0.9273,  1.4308],\n",
       "         [-0.5460, -2.4455],\n",
       "         [-0.0741,  0.5369],\n",
       "         [ 0.6823,  0.3214],\n",
       "         [-0.5464,  0.3381],\n",
       "         [ 0.5202,  0.6247],\n",
       "         [-0.3615, -0.6026]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard-coding the concatenation wouldn't work for other block sizes\n",
    "# So we generalize using torch.unbind\n",
    "# For block_size 3, torch.unbind(emb, dim=1) == [emb[:, 0, :], emb[:, 1, :], emb[:, 1, :]]\n",
    "torch.unbind(emb, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc862b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, dim=1), dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78118702",
   "metadata": {},
   "source": [
    "A more efficient way to concatenate the embeddings is to use `view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d340a036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7b5e40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One list of 18 numbers\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd413e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can represent this tensor with different dimensions\n",
    "# Two lists of 9 numbers\n",
    "a.view((2,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4f26fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 lists of 3 lists of 2 numbers\n",
    "a.view([3,3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e6124",
   "metadata": {},
   "source": [
    "`view()` is very efficent because of a tensor's `storage()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe617808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/3bkxx92d0z502px7sssbxnyw0000gn/T/ipykernel_27244/592914679.py:4: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the numbers are always stored in consecutive memory\n",
    "# tensor.view() only changes the view of the memory\n",
    "# No memory is copied, moved, or changed\n",
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80f5f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9273,  1.4308, -0.9273,  1.4308, -0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308, -0.5936, -0.9589],\n",
       "        [-0.9273,  1.4308, -0.5936, -0.9589, -0.2323,  0.9845],\n",
       "        [-0.5936, -0.9589, -0.2323,  0.9845, -0.2323,  0.9845],\n",
       "        [-0.2323,  0.9845, -0.2323,  0.9845, -0.3615, -0.6026],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308, -0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308, -0.0741,  0.5369],\n",
       "        [-0.9273,  1.4308, -0.0741,  0.5369, -0.4605,  0.0475],\n",
       "        [-0.0741,  0.5369, -0.4605,  0.0475,  0.5202,  0.6247],\n",
       "        [-0.4605,  0.0475,  0.5202,  0.6247, -1.8326,  0.5514],\n",
       "        [ 0.5202,  0.6247, -1.8326,  0.5514,  0.5202,  0.6247],\n",
       "        [-1.8326,  0.5514,  0.5202,  0.6247, -0.3615, -0.6026],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308, -0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308, -0.3615, -0.6026],\n",
       "        [-0.9273,  1.4308, -0.3615, -0.6026, -1.8326,  0.5514],\n",
       "        [-0.3615, -0.6026, -1.8326,  0.5514, -0.3615, -0.6026],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308, -0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308,  0.5202,  0.6247],\n",
       "        [-0.9273,  1.4308,  0.5202,  0.6247, -0.5460, -2.4455],\n",
       "        [ 0.5202,  0.6247, -0.5460, -2.4455, -0.3615, -0.6026],\n",
       "        [-0.5460, -2.4455, -0.3615, -0.6026,  1.6107, -0.0417],\n",
       "        [-0.3615, -0.6026,  1.6107, -0.0417, -0.5936, -0.9589],\n",
       "        [ 1.6107, -0.0417, -0.5936, -0.9589, -0.4605,  0.0475],\n",
       "        [-0.5936, -0.9589, -0.4605,  0.0475, -0.4605,  0.0475],\n",
       "        [-0.4605,  0.0475, -0.4605,  0.0475, -0.3615, -0.6026],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308, -0.9273,  1.4308],\n",
       "        [-0.9273,  1.4308, -0.9273,  1.4308, -0.5460, -2.4455],\n",
       "        [-0.9273,  1.4308, -0.5460, -2.4455, -0.0741,  0.5369],\n",
       "        [-0.5460, -2.4455, -0.0741,  0.5369,  0.6823,  0.3214],\n",
       "        [-0.0741,  0.5369,  0.6823,  0.3214, -0.5464,  0.3381],\n",
       "        [ 0.6823,  0.3214, -0.5464,  0.3381,  0.5202,  0.6247],\n",
       "        [-0.5464,  0.3381,  0.5202,  0.6247, -0.3615, -0.6026]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we can call view() on our input/embedding to do the same concatenation as before\n",
    "# but much more efficiently\n",
    "emb.view(32, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31348f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are equal operations\n",
    "emb.view(32,6) == torch.cat(torch.unbind(emb, dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c7d9e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3ace01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "924ca300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "097d4e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3747,  0.0097, -0.2228,  ..., -0.0455,  3.2644,  0.1557],\n",
       "        [ 1.2660, -0.8733,  3.0157,  ..., -1.6933,  5.1096, -1.6967],\n",
       "        [-2.5756, -0.6274, -0.3910,  ..., -4.0954, -1.4742,  2.1312],\n",
       "        ...,\n",
       "        [-2.3773, -0.3995,  1.9806,  ..., -1.8449,  1.0093, -0.2069],\n",
       "        [-1.7430, -2.0088,  1.1688,  ..., -2.2488,  0.8505, -0.2493],\n",
       "        [-0.7574, -0.5350,  3.0834,  ..., -2.5627,  2.2206, -1.1542]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can do the matrix multiplication to get our hidden layer\n",
    "# We can also do  emb.view(-1,6) and PyTorch will derive what that value should be\n",
    "h = emb.view(emb.shape[0],6) @ W1 + b1\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c849a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "502cf0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8798,  0.0097, -0.2191,  ..., -0.0455,  0.9971,  0.1545],\n",
       "        [ 0.8527, -0.7030,  0.9952,  ..., -0.9346,  0.9999, -0.9350],\n",
       "        [-0.9885, -0.5563, -0.3722,  ..., -0.9994, -0.9004,  0.9722],\n",
       "        ...,\n",
       "        [-0.9829, -0.3795,  0.9626,  ..., -0.9513,  0.7655, -0.2040],\n",
       "        [-0.9406, -0.9646,  0.8239,  ..., -0.9780,  0.6913, -0.2443],\n",
       "        [-0.6395, -0.4892,  0.9958,  ..., -0.9882,  0.9767, -0.8192]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We apply a tanh so that the values are between -1 and 1\n",
    "# Each example gets a tanh applied to it\n",
    "h = torch.tanh(h)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "787a2172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall that we arbitrarily chose 100 nodes for the hidden layer\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6091f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should always double-check that the broadcasting that occurs\n",
    "# when the bias `b` is added is correct\n",
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d925f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c52e94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6, 100 <-- W1\n",
    "# 1, 100 <-- b1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6740a",
   "metadata": {},
   "source": [
    "## Constructing the Final Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2e119ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W1 is a [6,100], meaning it has 100 outputs\n",
    "# So W2 must take in 100 outputs as inputs, and return 27 possible values\n",
    "# (since we have 27 possible characters)\n",
    "W2 = torch.rand((100, 27))\n",
    "b2 = torch.rand(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53573522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `logits` are the outputs of this neural net\n",
    "# Recall h = tanh(emb @ W1 + b1), where `emb` contains the inputs\n",
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1901e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each input example (32 total), the output can be one of 27 values\n",
    "# (a value is generated for each of the 27 characters)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "436289c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the logits to get \"fake counts\"\n",
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46b6ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then normalize the counts to get a probability\n",
    "# dim=1 because that is the final output\n",
    "probs = counts / counts.sum(dim=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "912db445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb4e8339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.9618e-04, 1.2329e-02, 1.2944e-01, 4.9393e-03, 2.0572e-01, 2.8765e-04,\n",
       "         5.2524e-02, 4.9635e-03, 1.1636e-04, 1.5191e-02, 2.4567e-04, 2.0490e-02,\n",
       "         2.5583e-01, 1.6568e-02, 5.1502e-03, 5.3125e-04, 2.5418e-03, 9.2257e-04,\n",
       "         7.6164e-04, 1.0799e-01, 1.3748e-02, 1.4347e-03, 1.0768e-01, 1.5232e-02,\n",
       "         1.4127e-02, 1.3523e-04, 1.0701e-02],\n",
       "        [4.9310e-04, 5.9830e-02, 9.0055e-03, 2.1468e-03, 7.1099e-02, 1.2801e-02,\n",
       "         7.2743e-03, 1.3667e-02, 8.6591e-03, 1.8418e-04, 4.1736e-03, 2.1978e-01,\n",
       "         5.9718e-03, 1.1478e-01, 2.2109e-03, 6.6828e-03, 2.7476e-02, 6.4243e-03,\n",
       "         2.6111e-03, 4.7357e-02, 8.1693e-03, 6.2603e-03, 1.1429e-01, 7.2644e-03,\n",
       "         1.9630e-01, 7.3732e-04, 4.4357e-02],\n",
       "        [3.0622e-04, 3.5605e-05, 1.2429e-01, 3.2011e-04, 2.5475e-01, 5.3287e-04,\n",
       "         3.1936e-03, 6.3487e-03, 5.4305e-06, 1.6503e-03, 2.4819e-05, 4.9178e-03,\n",
       "         9.9153e-02, 1.0857e-03, 5.2974e-04, 9.8552e-03, 2.2048e-02, 6.3814e-04,\n",
       "         8.0811e-03, 5.7998e-03, 8.4251e-03, 1.7984e-03, 1.3388e-02, 4.5758e-03,\n",
       "         2.9094e-02, 1.2887e-04, 3.9903e-01],\n",
       "        [6.4714e-05, 4.7808e-05, 1.3753e-02, 2.1206e-03, 2.4386e-04, 4.1393e-05,\n",
       "         1.2800e-02, 4.8395e-04, 5.9441e-04, 3.7431e-03, 1.4863e-02, 3.7669e-03,\n",
       "         7.2314e-01, 1.7141e-01, 7.8007e-04, 1.7599e-03, 6.9434e-03, 4.6510e-06,\n",
       "         2.0073e-02, 1.2847e-03, 2.2678e-03, 9.8129e-04, 9.0030e-03, 3.6000e-04,\n",
       "         1.2273e-03, 8.1992e-03, 4.6921e-05],\n",
       "        [1.1000e-03, 5.3272e-02, 5.8358e-02, 2.3044e-03, 7.2067e-02, 5.3056e-03,\n",
       "         5.2365e-03, 1.0364e-02, 1.0251e-02, 1.3992e-03, 6.0280e-03, 4.0374e-02,\n",
       "         2.3423e-02, 8.3368e-02, 6.9807e-04, 1.0064e-02, 1.4661e-02, 6.5699e-03,\n",
       "         2.6471e-02, 1.0121e-01, 4.9629e-03, 2.2214e-02, 4.0578e-02, 1.6893e-02,\n",
       "         3.0579e-01, 1.4170e-03, 7.5621e-02],\n",
       "        [3.9618e-04, 1.2329e-02, 1.2944e-01, 4.9393e-03, 2.0572e-01, 2.8765e-04,\n",
       "         5.2524e-02, 4.9635e-03, 1.1636e-04, 1.5191e-02, 2.4567e-04, 2.0490e-02,\n",
       "         2.5583e-01, 1.6568e-02, 5.1502e-03, 5.3125e-04, 2.5418e-03, 9.2257e-04,\n",
       "         7.6164e-04, 1.0799e-01, 1.3748e-02, 1.4347e-03, 1.0768e-01, 1.5232e-02,\n",
       "         1.4127e-02, 1.3523e-04, 1.0701e-02],\n",
       "        [9.6835e-05, 1.0676e-02, 1.6604e-02, 2.4833e-03, 3.9939e-01, 2.5158e-04,\n",
       "         7.7006e-02, 1.0234e-02, 3.5330e-04, 1.3274e-03, 1.8207e-04, 4.2229e-02,\n",
       "         4.7332e-02, 4.5428e-02, 2.0300e-03, 1.1829e-03, 3.3426e-03, 3.2797e-04,\n",
       "         1.7669e-03, 1.4029e-01, 6.1351e-03, 2.5955e-03, 6.2099e-02, 7.2455e-03,\n",
       "         3.2185e-02, 9.8490e-05, 8.7102e-02],\n",
       "        [9.7719e-05, 6.3992e-04, 9.4528e-03, 1.3402e-03, 1.0802e-01, 1.5776e-04,\n",
       "         2.1635e-03, 1.0164e-03, 1.4927e-04, 1.7001e-03, 5.0727e-05, 2.2283e-03,\n",
       "         1.0371e-01, 1.0242e-02, 1.0382e-04, 3.7705e-04, 1.5827e-03, 5.7248e-04,\n",
       "         1.7661e-03, 3.9960e-02, 3.7371e-03, 1.2294e-03, 4.3213e-02, 2.7697e-03,\n",
       "         1.3692e-02, 6.5854e-05, 6.4996e-01],\n",
       "        [4.9713e-05, 5.0001e-04, 5.6663e-02, 2.6428e-03, 1.4418e-01, 1.8950e-04,\n",
       "         2.3705e-02, 3.4386e-02, 1.3322e-04, 1.5305e-03, 1.9886e-04, 1.7333e-02,\n",
       "         1.7820e-01, 1.0392e-01, 1.0276e-04, 8.9704e-03, 2.2747e-02, 4.0009e-04,\n",
       "         4.5905e-02, 4.5308e-02, 1.0357e-03, 3.0017e-03, 1.4636e-02, 1.6758e-03,\n",
       "         1.5054e-01, 2.2174e-02, 1.1988e-01],\n",
       "        [3.9721e-03, 1.9694e-02, 4.8290e-01, 1.7464e-03, 1.0363e-02, 1.1888e-03,\n",
       "         1.3936e-03, 2.3192e-03, 3.1837e-03, 2.1056e-02, 2.6376e-02, 4.9199e-04,\n",
       "         2.2536e-01, 8.9224e-03, 9.8780e-03, 4.0581e-03, 2.9495e-03, 3.0786e-03,\n",
       "         1.2190e-02, 2.2225e-02, 7.5364e-02, 1.5443e-04, 9.0406e-03, 3.4092e-02,\n",
       "         1.4630e-02, 2.6286e-03, 7.4571e-04],\n",
       "        [1.8712e-04, 1.8331e-03, 3.0562e-02, 5.3153e-02, 3.8398e-02, 9.2785e-04,\n",
       "         2.4305e-01, 9.3567e-02, 1.2999e-03, 3.4433e-03, 1.1531e-03, 1.0924e-01,\n",
       "         1.4597e-02, 8.2641e-02, 2.1753e-04, 9.3252e-02, 1.1705e-03, 4.9647e-04,\n",
       "         4.1429e-02, 1.5668e-02, 3.3073e-03, 3.4801e-03, 1.0490e-02, 3.3154e-03,\n",
       "         7.4491e-02, 3.8602e-02, 4.0025e-02],\n",
       "        [3.3086e-04, 1.9456e-02, 4.2593e-01, 5.1172e-03, 2.8724e-02, 1.4365e-03,\n",
       "         2.0060e-03, 8.0763e-04, 6.0268e-03, 1.3410e-03, 9.9810e-04, 4.2228e-02,\n",
       "         9.0951e-02, 2.2031e-02, 9.8533e-06, 2.8060e-04, 1.5909e-02, 4.4130e-04,\n",
       "         1.5584e-02, 8.3908e-02, 5.8110e-03, 4.1440e-03, 7.2119e-02, 4.9423e-04,\n",
       "         2.5702e-03, 5.9423e-04, 1.5075e-01],\n",
       "        [3.9618e-04, 1.2329e-02, 1.2944e-01, 4.9393e-03, 2.0572e-01, 2.8765e-04,\n",
       "         5.2524e-02, 4.9635e-03, 1.1636e-04, 1.5191e-02, 2.4567e-04, 2.0490e-02,\n",
       "         2.5583e-01, 1.6568e-02, 5.1502e-03, 5.3125e-04, 2.5418e-03, 9.2257e-04,\n",
       "         7.6164e-04, 1.0799e-01, 1.3748e-02, 1.4347e-03, 1.0768e-01, 1.5232e-02,\n",
       "         1.4127e-02, 1.3523e-04, 1.0701e-02],\n",
       "        [3.2452e-04, 5.1865e-02, 8.9029e-03, 1.5153e-03, 1.1146e-01, 5.8006e-03,\n",
       "         1.5297e-02, 1.1756e-02, 4.7969e-03, 3.2750e-04, 3.1939e-03, 1.9920e-01,\n",
       "         7.3504e-03, 1.0692e-01, 1.8303e-03, 4.5776e-03, 2.7707e-02, 4.2126e-03,\n",
       "         1.5843e-03, 6.1935e-02, 5.3638e-03, 5.2105e-03, 1.2238e-01, 6.9987e-03,\n",
       "         1.7746e-01, 5.0116e-04, 5.1525e-02],\n",
       "        [3.5191e-04, 1.0410e-03, 7.6748e-01, 3.6443e-04, 1.2856e-02, 2.8785e-04,\n",
       "         6.0474e-04, 1.8179e-03, 1.4040e-05, 2.5152e-03, 5.0298e-05, 2.6505e-03,\n",
       "         6.3047e-03, 1.7325e-03, 2.3758e-04, 1.3092e-03, 1.6122e-03, 2.4715e-03,\n",
       "         3.6439e-04, 5.2288e-04, 6.8501e-03, 1.1609e-03, 3.1134e-03, 1.8311e-03,\n",
       "         7.7668e-03, 1.8601e-05, 1.7467e-01],\n",
       "        [5.7472e-03, 1.5513e-03, 7.7902e-02, 5.7870e-03, 1.8049e-04, 1.8866e-03,\n",
       "         4.2392e-02, 2.6647e-01, 2.0193e-02, 9.3226e-04, 2.0920e-03, 3.9186e-02,\n",
       "         3.5558e-03, 3.1121e-02, 9.1168e-05, 2.5197e-01, 2.4132e-02, 7.3394e-04,\n",
       "         6.1029e-02, 2.4525e-03, 3.7750e-02, 8.2810e-02, 5.8557e-04, 1.8773e-04,\n",
       "         1.1458e-02, 2.5365e-02, 2.4358e-03],\n",
       "        [3.9618e-04, 1.2329e-02, 1.2944e-01, 4.9393e-03, 2.0572e-01, 2.8765e-04,\n",
       "         5.2524e-02, 4.9635e-03, 1.1636e-04, 1.5191e-02, 2.4567e-04, 2.0490e-02,\n",
       "         2.5583e-01, 1.6568e-02, 5.1502e-03, 5.3125e-04, 2.5418e-03, 9.2257e-04,\n",
       "         7.6164e-04, 1.0799e-01, 1.3748e-02, 1.4347e-03, 1.0768e-01, 1.5232e-02,\n",
       "         1.4127e-02, 1.3523e-04, 1.0701e-02],\n",
       "        [9.1658e-05, 9.5166e-03, 9.9459e-03, 2.3999e-03, 5.3662e-01, 7.8649e-05,\n",
       "         6.1789e-02, 1.6140e-02, 3.3762e-04, 9.6682e-04, 1.0878e-04, 5.2629e-02,\n",
       "         2.2832e-02, 3.9820e-02, 9.2289e-04, 1.3607e-03, 2.4584e-03, 1.6417e-04,\n",
       "         2.1506e-03, 1.1333e-01, 3.2597e-03, 2.1692e-03, 3.5615e-02, 3.7792e-03,\n",
       "         3.6940e-02, 2.1219e-04, 4.4360e-02],\n",
       "        [8.8525e-03, 4.1266e-01, 3.3783e-02, 3.5547e-03, 1.2223e-01, 4.1400e-02,\n",
       "         7.8709e-05, 1.6235e-02, 4.1521e-02, 2.5113e-05, 3.4863e-03, 8.5183e-02,\n",
       "         2.9062e-03, 2.8581e-03, 3.4499e-05, 6.7578e-02, 1.1218e-02, 2.7664e-02,\n",
       "         2.4259e-02, 1.4196e-02, 2.1920e-03, 7.3842e-03, 1.7871e-02, 2.1528e-03,\n",
       "         1.7468e-02, 7.6558e-03, 2.5553e-02],\n",
       "        [2.4937e-03, 2.4563e-04, 5.9662e-02, 2.2341e-04, 3.9158e-02, 2.5549e-03,\n",
       "         1.4894e-04, 8.9644e-02, 4.4608e-04, 1.3533e-04, 2.4887e-04, 7.4712e-03,\n",
       "         2.6981e-03, 3.2647e-05, 5.1606e-05, 6.0733e-02, 2.8155e-03, 1.4433e-01,\n",
       "         3.7777e-01, 5.1333e-03, 6.5320e-03, 4.3505e-03, 4.1114e-04, 7.7324e-05,\n",
       "         1.3522e-01, 3.4673e-04, 5.7068e-02],\n",
       "        [2.7064e-04, 6.2809e-05, 9.3741e-03, 9.6751e-02, 3.7274e-04, 3.2234e-04,\n",
       "         3.4019e-03, 3.6316e-04, 1.1870e-03, 8.5201e-04, 8.3330e-03, 3.8013e-03,\n",
       "         3.9983e-03, 2.3496e-02, 7.6221e-04, 3.4810e-02, 2.5592e-01, 3.0056e-05,\n",
       "         3.8217e-01, 1.0289e-02, 6.8501e-04, 2.3373e-02, 2.8509e-03, 4.8923e-05,\n",
       "         7.7405e-04, 1.3497e-01, 7.2243e-04],\n",
       "        [2.4437e-03, 6.9899e-03, 2.2485e-01, 4.4345e-02, 7.9688e-03, 4.2421e-03,\n",
       "         1.5196e-04, 5.7341e-04, 1.7886e-02, 5.2033e-05, 1.1563e-01, 2.9296e-03,\n",
       "         1.2041e-02, 3.1899e-02, 2.3266e-03, 6.5381e-03, 9.8379e-02, 6.3343e-03,\n",
       "         2.3146e-01, 1.0868e-01, 1.0411e-03, 1.7285e-03, 2.4358e-02, 4.6026e-03,\n",
       "         4.9112e-03, 2.4570e-03, 3.5184e-02],\n",
       "        [6.9813e-03, 8.2199e-04, 2.8399e-02, 1.4622e-03, 1.9250e-03, 1.0917e-02,\n",
       "         5.3063e-04, 4.8710e-02, 1.0828e-03, 1.1775e-03, 7.1997e-04, 1.1359e-03,\n",
       "         4.2785e-04, 1.1846e-04, 1.7714e-03, 5.3227e-01, 3.6357e-03, 3.2610e-03,\n",
       "         2.8013e-01, 1.9969e-03, 5.0578e-03, 2.7081e-02, 8.7674e-04, 1.2211e-02,\n",
       "         2.3038e-02, 7.5464e-04, 3.5054e-03],\n",
       "        [9.6751e-04, 4.3027e-05, 2.5882e-01, 2.0768e-03, 1.8100e-03, 3.5008e-04,\n",
       "         3.8139e-03, 1.9552e-02, 2.8842e-03, 6.1755e-04, 8.8745e-03, 2.5925e-03,\n",
       "         3.5203e-03, 1.4976e-02, 1.2368e-03, 9.2877e-02, 9.7888e-02, 1.4273e-04,\n",
       "         4.6728e-01, 7.1433e-03, 4.4283e-03, 6.1471e-04, 5.2505e-04, 1.8170e-04,\n",
       "         1.1377e-03, 5.1753e-03, 4.7229e-04],\n",
       "        [9.1726e-04, 7.8224e-03, 4.7938e-01, 1.9835e-03, 6.7243e-03, 3.4022e-03,\n",
       "         1.7810e-03, 1.7289e-02, 2.9284e-03, 1.1090e-04, 9.9599e-04, 6.6288e-03,\n",
       "         2.2139e-03, 1.1089e-02, 3.3557e-05, 3.5367e-02, 6.4537e-02, 7.7777e-03,\n",
       "         2.1306e-01, 2.9599e-02, 1.3606e-02, 5.0051e-03, 1.0834e-02, 1.3480e-04,\n",
       "         3.4201e-02, 8.6338e-03, 3.3943e-02],\n",
       "        [3.9618e-04, 1.2329e-02, 1.2944e-01, 4.9393e-03, 2.0572e-01, 2.8765e-04,\n",
       "         5.2524e-02, 4.9635e-03, 1.1636e-04, 1.5191e-02, 2.4567e-04, 2.0490e-02,\n",
       "         2.5583e-01, 1.6568e-02, 5.1502e-03, 5.3125e-04, 2.5418e-03, 9.2257e-04,\n",
       "         7.6164e-04, 1.0799e-01, 1.3748e-02, 1.4347e-03, 1.0768e-01, 1.5232e-02,\n",
       "         1.4127e-02, 1.3523e-04, 1.0701e-02],\n",
       "        [4.8080e-03, 1.5146e-01, 1.5702e-02, 1.2096e-02, 7.2016e-02, 1.9843e-02,\n",
       "         2.6080e-04, 1.7398e-02, 1.3692e-01, 4.4363e-05, 2.9302e-03, 1.5218e-01,\n",
       "         9.6903e-04, 1.0590e-01, 2.1316e-03, 3.7572e-02, 1.1707e-02, 3.7656e-02,\n",
       "         2.1544e-03, 2.4257e-02, 7.7263e-03, 3.5080e-02, 9.3859e-02, 2.3615e-03,\n",
       "         3.8693e-02, 5.2377e-03, 9.0460e-03],\n",
       "        [7.9282e-04, 1.8789e-05, 4.0423e-02, 5.6560e-05, 1.1871e-01, 1.5298e-03,\n",
       "         3.3356e-04, 7.4061e-03, 2.5610e-06, 1.2243e-04, 3.2580e-05, 1.1785e-03,\n",
       "         8.4509e-03, 5.9768e-05, 1.2706e-04, 4.4296e-03, 7.0738e-03, 3.4513e-03,\n",
       "         2.4528e-03, 2.9911e-03, 2.1832e-03, 1.5895e-03, 1.4472e-03, 4.5509e-04,\n",
       "         4.8276e-03, 3.1300e-05, 7.8982e-01],\n",
       "        [2.2362e-04, 1.1414e-05, 6.4592e-03, 1.7682e-02, 1.8509e-04, 5.1960e-04,\n",
       "         5.2547e-03, 9.3060e-04, 4.2445e-03, 7.8522e-04, 2.3402e-02, 9.9948e-04,\n",
       "         2.0216e-02, 4.7549e-02, 1.9061e-03, 2.3710e-02, 1.1111e-01, 3.8707e-06,\n",
       "         3.5458e-01, 9.9115e-03, 8.1902e-04, 1.5140e-02, 8.7659e-04, 3.1496e-04,\n",
       "         2.5986e-04, 3.5285e-01, 6.3658e-05],\n",
       "        [4.7407e-04, 2.2089e-02, 1.8949e-01, 2.6869e-02, 2.7874e-02, 1.7206e-03,\n",
       "         2.7310e-03, 1.9586e-03, 1.7914e-03, 6.2252e-03, 4.0303e-03, 7.9091e-03,\n",
       "         1.3108e-01, 9.4034e-02, 9.0228e-04, 4.0383e-03, 1.2443e-02, 2.7133e-03,\n",
       "         2.7842e-02, 9.4587e-02, 1.0578e-02, 3.3828e-03, 1.4450e-02, 6.3695e-02,\n",
       "         4.2685e-02, 3.9848e-03, 2.0042e-01],\n",
       "        [1.1452e-04, 1.7957e-03, 6.7592e-02, 6.7759e-03, 1.5615e-02, 3.3718e-04,\n",
       "         8.9456e-02, 6.6482e-02, 8.1718e-04, 6.9084e-03, 1.7293e-03, 2.4858e-02,\n",
       "         4.4122e-02, 1.3404e-01, 9.5651e-05, 3.4639e-02, 5.2778e-03, 1.6574e-04,\n",
       "         2.8129e-01, 5.5222e-02, 7.4310e-04, 1.5846e-02, 8.1417e-03, 8.3353e-03,\n",
       "         5.4860e-02, 3.6930e-02, 3.7809e-02],\n",
       "        [4.7157e-04, 1.5298e-02, 2.0200e-01, 7.8426e-03, 1.6520e-02, 1.5549e-03,\n",
       "         1.8819e-03, 1.3564e-03, 2.3027e-02, 3.1998e-04, 4.2874e-03, 1.4435e-02,\n",
       "         2.5881e-02, 1.9566e-02, 1.2151e-04, 4.1931e-03, 8.2760e-02, 3.7814e-03,\n",
       "         1.6451e-01, 2.1527e-01, 2.3836e-03, 3.2566e-03, 1.0325e-02, 1.7354e-03,\n",
       "         1.3843e-02, 1.7553e-03, 1.6162e-01]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "25caff9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each row in probs now sum to 1\n",
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6392830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The correct answer of the next character is provided by Y\n",
    "# So for each row in probs, we need to get the probability that was generated for the output character\n",
    "# of each example (a row in probs)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51b82fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a list of indices to index into probs\n",
    "# We want to index into each example (32 examples total)\n",
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a43166b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8765e-04, 1.1478e-01, 1.0857e-03, 4.7808e-05, 1.1000e-03, 5.3125e-04,\n",
       "        4.7332e-02, 1.7001e-03, 1.4636e-02, 2.1056e-02, 1.8331e-03, 3.3086e-04,\n",
       "        1.2329e-02, 1.2238e-01, 1.0410e-03, 5.7472e-03, 1.5191e-02, 1.1333e-01,\n",
       "        4.1266e-01, 5.9662e-02, 3.2234e-04, 1.2041e-02, 4.2785e-04, 4.3027e-05,\n",
       "        9.1726e-04, 1.0799e-01, 3.7572e-02, 7.0738e-03, 4.2445e-03, 6.2252e-03,\n",
       "        1.7957e-03, 4.7157e-04])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then use Y as a list of indicies\n",
    "# This automatically grabs the probabiltiy assigned to each output character in Y, for each example\n",
    "probs[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e6ae87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ideal goal of training is to get all the probabilities of each correct character per example is 1 (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc97775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4410)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we calculate the negative log liklihood for loss\n",
    "# This is the loss we'd like to minimize\n",
    "loss = -probs[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e8b9b",
   "metadata": {},
   "source": [
    "## Complete Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5182e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3d1d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c26b52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 characters, each character has an embedding/representation of two floats\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "# 3 characters per input, 2 embeddings per character\n",
    "# 100 is an arbitrary number of nodes\n",
    "W1 = torch.randn((6,100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "\n",
    "# 100 inputs from previous layer, 27 possible characters as outputs\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1a2c143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of parameters in total\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036d66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
