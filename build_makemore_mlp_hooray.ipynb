{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b908cb-2c1d-4c2b-84b2-ea18867ea87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f35433-59bd-4577-bb93-03eca7539002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in all the names, as a list of names\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40047ee-fc04-4e80-a573-19052e8ae9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(words)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5213b782-cce5-4d0a-a3ab-50b29a3d8446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build character to integer mapping\n",
    "# First we combine all the names into one string, then create a set() (this keeps unique characters only)\n",
    "# Then we sort alphabetically\n",
    "chars = sorted(set(\"\".join(words)))\n",
    "\n",
    "# String to integer\n",
    "stoi = {c:i+1 for (i, c) in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4e9349-6c01-4bc3-889f-733804ea339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer to string\n",
    "itos = {i:c for (c,i) in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3345086",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb5b5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# Context length: how many previous characters do we use to predict the next character\n",
    "block_size = 3\n",
    "\n",
    "# Inputs to the neural net (the previous characters seen)\n",
    "X = []\n",
    "# The labels of the inputs to the neural net (the next character)\n",
    "Y = []\n",
    "\n",
    "# Create a dataset, mapping `block_size` characters -> next character\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    \n",
    "    # Initialize the context with empty characters\n",
    "    context = [stoi[\".\"]] * block_size\n",
    "    # We want the last characters of the name to be included in the dataset\n",
    "    # which is why we append \".\" to the end of the name\n",
    "    for w in word + \".\":\n",
    "        # Get the next character\n",
    "        ix = stoi[w]\n",
    "        \n",
    "        # Save the input and output\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "            \n",
    "        # Print the example\n",
    "        print(\"\".join(itos[i] for i in context) + \" ---> \" + itos[ix])\n",
    "        \n",
    "        # Remove the earliest character in the context, and append the newest character\n",
    "        # as the latest character in the context\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "# Inputs\n",
    "X = torch.tensor(X)\n",
    "# Labels\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ed7c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 3]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# We have x many input examples, with each with a context size `block_size`\n",
    "print(f\"Input shape: {X.shape}, {X.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d7531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([32]), torch.int64\n"
     ]
    }
   ],
   "source": [
    "# The next character is one of 27 possible characters\n",
    "print(f\"Labels shape: {Y.shape}, {Y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e14a4",
   "metadata": {},
   "source": [
    "## Building the Embedding Table `C`\n",
    "In the paper, 17,000 possible words are crammed into a 30-dimensional space.\n",
    "We have 27 possible characters, so let's cram them into a 2-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706c9aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1733,  2.0990],\n",
       "        [-1.0517, -0.5137],\n",
       "        [-0.4361, -0.3689],\n",
       "        [ 1.6064, -0.9127],\n",
       "        [ 0.8234, -0.9242],\n",
       "        [-1.1432,  0.8409],\n",
       "        [ 0.1157, -0.9679],\n",
       "        [-0.8842,  1.2050],\n",
       "        [-0.1721, -0.9472],\n",
       "        [ 2.7344, -0.2924],\n",
       "        [ 0.2427,  0.1372],\n",
       "        [ 0.9499,  0.5008],\n",
       "        [-1.3637, -0.6750],\n",
       "        [ 0.9408, -1.1901],\n",
       "        [ 1.3130, -0.9485],\n",
       "        [-0.3181,  0.7576],\n",
       "        [-0.5376,  0.5322],\n",
       "        [-0.4070, -0.4677],\n",
       "        [-1.9054, -0.1338],\n",
       "        [ 0.3915, -1.3050],\n",
       "        [-0.2548, -1.2440],\n",
       "        [-0.8101, -1.1608],\n",
       "        [ 0.5212, -0.2390],\n",
       "        [ 0.9280, -0.2610],\n",
       "        [-0.8942,  0.3725],\n",
       "        [ 2.2526,  0.8406],\n",
       "        [ 2.1230,  0.2043]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 27 possible characters, 2-dimensional space\n",
    "# Each character has a 2-dimenional embedding\n",
    "C = torch.randn((27, 2))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be366943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character g maps to 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.8842,  1.2050])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 'g'\n",
    "c_index = stoi[c]\n",
    "print(f\"Character {c} maps to {c_index}\")\n",
    "C[c_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24ad2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing into the embedding table `C` is the same as matrix multiplying\n",
    "# `C` with the one-hot encoding representation of the input character\n",
    "v = F.one_hot(torch.tensor(c_index), num_classes=27)\n",
    "v.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11319dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8842,  1.2050])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to cast the vector to a float since the embedding table C contains floats\n",
    "v.float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7679b9",
   "metadata": {},
   "source": [
    "Embedding a single character into the embedding table `C` is easy. Just use the integer representation of that character, and index into `C`. But how do we simultaneously embed `[32,3]` (32 examples, each of size 3, stored in array `X`) into `C`?\n",
    "\n",
    "In addition to integers, we can use lists to index into `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b70c525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4361, -0.3689],\n",
       "        [ 1.6064, -0.9127],\n",
       "        [ 0.8234, -0.9242]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets the rows at index 2, 3, and 4\n",
    "C[[2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df1f150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4361, -0.3689],\n",
       "        [ 1.6064, -0.9127],\n",
       "        [ 0.8234, -0.9242]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also index using Tensors\n",
    "C[torch.tensor([2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f21f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4361, -0.3689],\n",
       "        [-0.4361, -0.3689],\n",
       "        [-0.4361, -0.3689]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the same row multiple times\n",
    "C[[2,2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89bbac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall, X contains the characters as integers as input\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf02c925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape torch.Size([32, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1432,  0.8409]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1432,  0.8409],\n",
       "         [ 0.9408, -1.1901]],\n",
       "\n",
       "        [[-1.1432,  0.8409],\n",
       "         [ 0.9408, -1.1901],\n",
       "         [ 0.9408, -1.1901]],\n",
       "\n",
       "        [[ 0.9408, -1.1901],\n",
       "         [ 0.9408, -1.1901],\n",
       "         [-1.0517, -0.5137]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-0.3181,  0.7576]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-0.3181,  0.7576],\n",
       "         [-1.3637, -0.6750]],\n",
       "\n",
       "        [[-0.3181,  0.7576],\n",
       "         [-1.3637, -0.6750],\n",
       "         [ 2.7344, -0.2924]],\n",
       "\n",
       "        [[-1.3637, -0.6750],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [ 0.5212, -0.2390]],\n",
       "\n",
       "        [[ 2.7344, -0.2924],\n",
       "         [ 0.5212, -0.2390],\n",
       "         [ 2.7344, -0.2924]],\n",
       "\n",
       "        [[ 0.5212, -0.2390],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [-1.0517, -0.5137]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.0517, -0.5137]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.0517, -0.5137],\n",
       "         [ 0.5212, -0.2390]],\n",
       "\n",
       "        [[-1.0517, -0.5137],\n",
       "         [ 0.5212, -0.2390],\n",
       "         [-1.0517, -0.5137]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [ 2.7344, -0.2924]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [ 0.3915, -1.3050]],\n",
       "\n",
       "        [[ 2.7344, -0.2924],\n",
       "         [ 0.3915, -1.3050],\n",
       "         [-1.0517, -0.5137]],\n",
       "\n",
       "        [[ 0.3915, -1.3050],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-0.4361, -0.3689]],\n",
       "\n",
       "        [[-1.0517, -0.5137],\n",
       "         [-0.4361, -0.3689],\n",
       "         [-1.1432,  0.8409]],\n",
       "\n",
       "        [[-0.4361, -0.3689],\n",
       "         [-1.1432,  0.8409],\n",
       "         [-1.3637, -0.6750]],\n",
       "\n",
       "        [[-1.1432,  0.8409],\n",
       "         [-1.3637, -0.6750],\n",
       "         [-1.3637, -0.6750]],\n",
       "\n",
       "        [[-1.3637, -0.6750],\n",
       "         [-1.3637, -0.6750],\n",
       "         [-1.0517, -0.5137]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [ 0.3915, -1.3050]],\n",
       "\n",
       "        [[-1.1733,  2.0990],\n",
       "         [ 0.3915, -1.3050],\n",
       "         [-0.3181,  0.7576]],\n",
       "\n",
       "        [[ 0.3915, -1.3050],\n",
       "         [-0.3181,  0.7576],\n",
       "         [-0.5376,  0.5322]],\n",
       "\n",
       "        [[-0.3181,  0.7576],\n",
       "         [-0.5376,  0.5322],\n",
       "         [-0.1721, -0.9472]],\n",
       "\n",
       "        [[-0.5376,  0.5322],\n",
       "         [-0.1721, -0.9472],\n",
       "         [ 2.7344, -0.2924]],\n",
       "\n",
       "        [[-0.1721, -0.9472],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [-1.0517, -0.5137]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can index into the embedding table `C` using multi-dimensional tensors too\n",
    "# The character integers in X is used as the indices into C\n",
    "print(\"X.shape\", X.shape)\n",
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "153492e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [32, 3] was the shape of the input X, then each input has an embedding of 2\n",
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d40b09b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 2nd character in the 7th example\n",
    "example_index = 7\n",
    "character_index = 2\n",
    "X[example_index,character_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ac3582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the character representation of the integer\n",
    "itos[X[example_index,character_index].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a11182dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3637, -0.6750])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the *embedding*of the 2nd character in the 7th example\n",
    "C[X][example_index,character_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3943da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3637, -0.6750])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C[12] is equivalent to C[X[7,2]]\n",
    "C[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2de2444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We created our embedding table integrated with our example inputs!\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f5a6d",
   "metadata": {},
   "source": [
    "## Contructing the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4497a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "# 3 characters per input, and each characters has two floats that represent it (it's embedding)\n",
    "# 3*2 = 6 outputs in the first layer\n",
    "# So the hidden layer has to take in 6 inputs\n",
    "# The number of out put nodes is a variable, we arbitrary choose 100 for now\n",
    "W1 = torch.randn((6,100))\n",
    "# Biases, should match the size of the hidden layer\n",
    "b = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff3911d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The goal is to be able to do:\n",
    "# emb @ W1 + b\n",
    "# with `@` indicating matrix multiply\n",
    "# and `emb` as our input\n",
    "# We can't do this directly since their shapes don't match correctly\n",
    "# The goal is to get the input/embedding of shape [32,6]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b26ea7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7168f7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1432,  0.8409],\n",
       "        [ 0.9408, -1.1901],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-0.3181,  0.7576],\n",
       "        [-1.3637, -0.6750],\n",
       "        [ 2.7344, -0.2924],\n",
       "        [ 0.5212, -0.2390],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.0517, -0.5137],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [ 2.7344, -0.2924],\n",
       "        [ 0.3915, -1.3050],\n",
       "        [-1.0517, -0.5137],\n",
       "        [-0.4361, -0.3689],\n",
       "        [-1.1432,  0.8409],\n",
       "        [-1.3637, -0.6750],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990],\n",
       "        [ 0.3915, -1.3050],\n",
       "        [-0.3181,  0.7576],\n",
       "        [-0.5376,  0.5322],\n",
       "        [-0.1721, -0.9472]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To do this, we can concatenate the three characters and their embeddings\n",
    "# This grabs all the examples, indexes that into index 0 (first character)\n",
    "# then grabs all the embeddings of the first character for all the examples\n",
    "emb[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70ac1e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets the embeddings of all the first characters in each example\n",
    "emb[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ac67b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to concatenate the embeddings of all the characters\n",
    "# Each emb[:, x, :] has shape [32, 2]\n",
    "# and we want to concatenate cross the dim=1 to get [32,6]\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 1, :]], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15fae181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1432,  0.8409],\n",
       "         [ 0.9408, -1.1901],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-0.3181,  0.7576],\n",
       "         [-1.3637, -0.6750],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [ 0.5212, -0.2390],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [ 0.3915, -1.3050],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-0.4361, -0.3689],\n",
       "         [-1.1432,  0.8409],\n",
       "         [-1.3637, -0.6750],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [ 0.3915, -1.3050],\n",
       "         [-0.3181,  0.7576],\n",
       "         [-0.5376,  0.5322],\n",
       "         [-0.1721, -0.9472]]),\n",
       " tensor([[-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1432,  0.8409],\n",
       "         [ 0.9408, -1.1901],\n",
       "         [ 0.9408, -1.1901],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-0.3181,  0.7576],\n",
       "         [-1.3637, -0.6750],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [ 0.5212, -0.2390],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.0517, -0.5137],\n",
       "         [ 0.5212, -0.2390],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [ 0.3915, -1.3050],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-0.4361, -0.3689],\n",
       "         [-1.1432,  0.8409],\n",
       "         [-1.3637, -0.6750],\n",
       "         [-1.3637, -0.6750],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.1733,  2.0990],\n",
       "         [ 0.3915, -1.3050],\n",
       "         [-0.3181,  0.7576],\n",
       "         [-0.5376,  0.5322],\n",
       "         [-0.1721, -0.9472],\n",
       "         [ 2.7344, -0.2924]]),\n",
       " tensor([[-1.1733,  2.0990],\n",
       "         [-1.1432,  0.8409],\n",
       "         [ 0.9408, -1.1901],\n",
       "         [ 0.9408, -1.1901],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-0.3181,  0.7576],\n",
       "         [-1.3637, -0.6750],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [ 0.5212, -0.2390],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-1.1733,  2.0990],\n",
       "         [-1.0517, -0.5137],\n",
       "         [ 0.5212, -0.2390],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-1.1733,  2.0990],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [ 0.3915, -1.3050],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-0.4361, -0.3689],\n",
       "         [-1.1432,  0.8409],\n",
       "         [-1.3637, -0.6750],\n",
       "         [-1.3637, -0.6750],\n",
       "         [-1.0517, -0.5137],\n",
       "         [-1.1733,  2.0990],\n",
       "         [ 0.3915, -1.3050],\n",
       "         [-0.3181,  0.7576],\n",
       "         [-0.5376,  0.5322],\n",
       "         [-0.1721, -0.9472],\n",
       "         [ 2.7344, -0.2924],\n",
       "         [-1.0517, -0.5137]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard-coding the concatenation wouldn't work for other block sizes\n",
    "# So we generalize using torch.unbind\n",
    "# For block_size 3, torch.unbind(emb, dim=1) == [emb[:, 0, :], emb[:, 1, :], emb[:, 1, :]]\n",
    "torch.unbind(emb, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc862b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, dim=1), dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78118702",
   "metadata": {},
   "source": [
    "A more efficient way to concatenate the embeddings is to use `view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d340a036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7b5e40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One list of 18 numbers\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd413e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can represent this tensor with different dimensions\n",
    "# Two lists of 9 numbers\n",
    "a.view((2,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4f26fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 lists of 3 lists of 2 numbers\n",
    "a.view([3,3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e6124",
   "metadata": {},
   "source": [
    "`view()` is very efficent because of a tensor's `storage()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe617808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the numbers are always stored in consecutive memory\n",
    "# tensor.view() only changes the view of the memory\n",
    "# No memory is copied, moved, or changed\n",
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80f5f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1733,  2.0990, -1.1733,  2.0990, -1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990, -1.1432,  0.8409],\n",
       "        [-1.1733,  2.0990, -1.1432,  0.8409,  0.9408, -1.1901],\n",
       "        [-1.1432,  0.8409,  0.9408, -1.1901,  0.9408, -1.1901],\n",
       "        [ 0.9408, -1.1901,  0.9408, -1.1901, -1.0517, -0.5137],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990, -1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990, -0.3181,  0.7576],\n",
       "        [-1.1733,  2.0990, -0.3181,  0.7576, -1.3637, -0.6750],\n",
       "        [-0.3181,  0.7576, -1.3637, -0.6750,  2.7344, -0.2924],\n",
       "        [-1.3637, -0.6750,  2.7344, -0.2924,  0.5212, -0.2390],\n",
       "        [ 2.7344, -0.2924,  0.5212, -0.2390,  2.7344, -0.2924],\n",
       "        [ 0.5212, -0.2390,  2.7344, -0.2924, -1.0517, -0.5137],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990, -1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990, -1.0517, -0.5137],\n",
       "        [-1.1733,  2.0990, -1.0517, -0.5137,  0.5212, -0.2390],\n",
       "        [-1.0517, -0.5137,  0.5212, -0.2390, -1.0517, -0.5137],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990, -1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990,  2.7344, -0.2924],\n",
       "        [-1.1733,  2.0990,  2.7344, -0.2924,  0.3915, -1.3050],\n",
       "        [ 2.7344, -0.2924,  0.3915, -1.3050, -1.0517, -0.5137],\n",
       "        [ 0.3915, -1.3050, -1.0517, -0.5137, -0.4361, -0.3689],\n",
       "        [-1.0517, -0.5137, -0.4361, -0.3689, -1.1432,  0.8409],\n",
       "        [-0.4361, -0.3689, -1.1432,  0.8409, -1.3637, -0.6750],\n",
       "        [-1.1432,  0.8409, -1.3637, -0.6750, -1.3637, -0.6750],\n",
       "        [-1.3637, -0.6750, -1.3637, -0.6750, -1.0517, -0.5137],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990, -1.1733,  2.0990],\n",
       "        [-1.1733,  2.0990, -1.1733,  2.0990,  0.3915, -1.3050],\n",
       "        [-1.1733,  2.0990,  0.3915, -1.3050, -0.3181,  0.7576],\n",
       "        [ 0.3915, -1.3050, -0.3181,  0.7576, -0.5376,  0.5322],\n",
       "        [-0.3181,  0.7576, -0.5376,  0.5322, -0.1721, -0.9472],\n",
       "        [-0.5376,  0.5322, -0.1721, -0.9472,  2.7344, -0.2924],\n",
       "        [-0.1721, -0.9472,  2.7344, -0.2924, -1.0517, -0.5137]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we can call view() on our input/embedding to do the same concatenation as before\n",
    "# but much more efficiently\n",
    "emb.view(32, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31348f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are equal operations\n",
    "emb.view(32,6) == torch.cat(torch.unbind(emb, dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c7d9e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3ace01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "924ca300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "097d4e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2113,  1.6906, -4.3554,  ..., -2.3010, -3.7414, -5.1612],\n",
       "        [ 1.4776,  0.7002, -3.1253,  ..., -0.2176, -2.9236, -3.8324],\n",
       "        [-1.7211, -1.5596, -0.3741,  ...,  4.1063,  1.1268, -0.3361],\n",
       "        ...,\n",
       "        [-0.3858, -0.4014, -0.5281,  ...,  3.1009,  0.5141,  1.0116],\n",
       "        [-2.5479, -0.6621, -0.7186,  ...,  3.1786,  3.4945,  2.6015],\n",
       "        [ 0.4771,  0.7597, -1.3006,  ...,  1.1065,  0.0914,  3.3237]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can do the matrix multiplication to get our hidden layer\n",
    "h = emb.view(32,6) @ W1 + b\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c849a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cf0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
